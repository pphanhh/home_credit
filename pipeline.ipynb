{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:00:25.847118Z",
     "iopub.status.busy": "2024-12-08T11:00:25.846096Z",
     "iopub.status.idle": "2024-12-08T11:00:26.289581Z",
     "shell.execute_reply": "2024-12-08T11:00:26.288026Z",
     "shell.execute_reply.started": "2024-12-08T11:00:25.847067Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import gc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Intel only\n",
    "# !pip install scikit-learn-intelex\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:00:26.292873Z",
     "iopub.status.busy": "2024-12-08T11:00:26.292101Z",
     "iopub.status.idle": "2024-12-08T11:00:26.299607Z",
     "shell.execute_reply": "2024-12-08T11:00:26.298124Z",
     "shell.execute_reply.started": "2024-12-08T11:00:26.292826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:00:26.301537Z",
     "iopub.status.busy": "2024-12-08T11:00:26.301128Z",
     "iopub.status.idle": "2024-12-08T11:00:26.323429Z",
     "shell.execute_reply": "2024-12-08T11:00:26.321655Z",
     "shell.execute_reply.started": "2024-12-08T11:00:26.301498Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/quanghung20gg/Documents/new/datavis_final/datavis_final/eda/v1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:00:26.326301Z",
     "iopub.status.busy": "2024-12-08T11:00:26.325027Z",
     "iopub.status.idle": "2024-12-08T11:00:26.335221Z",
     "shell.execute_reply": "2024-12-08T11:00:26.334050Z",
     "shell.execute_reply.started": "2024-12-08T11:00:26.326251Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:00:26.338963Z",
     "iopub.status.busy": "2024-12-08T11:00:26.338507Z",
     "iopub.status.idle": "2024-12-08T11:00:26.351797Z",
     "shell.execute_reply": "2024-12-08T11:00:26.350236Z",
     "shell.execute_reply.started": "2024-12-08T11:00:26.338921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "UPSAMPLE_RATIO = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:00:26.354452Z",
     "iopub.status.busy": "2024-12-08T11:00:26.354048Z",
     "iopub.status.idle": "2024-12-08T11:00:26.369513Z",
     "shell.execute_reply": "2024-12-08T11:00:26.368177Z",
     "shell.execute_reply.started": "2024-12-08T11:00:26.354419Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ROOT = '/kaggle/input/dseb-64-data-preparation-final-project/dseb63_final_project_DP_dataset/dseb63_final_project_DP_dataset'\n",
    "ROOT = '../../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APP PREV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:00:26.371717Z",
     "iopub.status.busy": "2024-12-08T11:00:26.371321Z",
     "iopub.status.idle": "2024-12-08T11:00:26.433122Z",
     "shell.execute_reply": "2024-12-08T11:00:26.431384Z",
     "shell.execute_reply.started": "2024-12-08T11:00:26.371679Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_app_prev():\n",
    "    prev_app = pd.read_csv(os.path.join(ROOT, \"dseb63_previous_application.csv\"))\n",
    "    prev_app['DATE_DIFF'] = prev_app['DAYS_TERMINATION'] - prev_app['DAYS_LAST_DUE']\n",
    "    good_replace = ['Gardening', 'Animals', 'Insurance', 'Medicine', 'Fitness', 'Direct Sales', 'Additional Service', 'Education', 'Weapon', ]\n",
    "    good_replace_2 = ['Vehicles','Homewares','Medical Supplies','Jewelry', 'Tourism', 'Office Appliances']\n",
    "    # good_replace+=good_replace_2\n",
    "    \n",
    "    prev_app['NAME_GOODS_CATEGORY'] = prev_app['NAME_GOODS_CATEGORY'].replace(good_replace, 'Other')\n",
    "    prev_app['NAME_CASH_LOAN_PURPOSE'].replace({'Wedding / gift / holiday':'Journey', 'Hobby': 'Everyday expenses'}, inplace=True)\n",
    "    \n",
    "    loan_purpose = ['Refusal to name the goal', 'Money for a third person', 'Buying a garage', 'Buying a garage', 'Gasification / water supply', 'Business development', 'Buying a holiday home / land', 'Furniture', 'Car repairs', 'Buying a home',  'Purchase of electronic equipment', 'Journey', 'Education', 'Payments on other loans', 'Medicine', 'Building a house or an annex']\n",
    "    \n",
    "    prev_app['NAME_CASH_LOAN_PURPOSE'] = prev_app['NAME_CASH_LOAN_PURPOSE'].replace(loan_purpose, 'Other')\n",
    "    prev_app['NAME_CASH_LOAN_PURPOSE'] = prev_app['NAME_CASH_LOAN_PURPOSE'].replace(['Buying a new car', 'Buying a used car'], 'Buying a car')\n",
    "    prev_app['FLAG_LAST_APPL_PER_CONTRACT'] = prev_app['FLAG_LAST_APPL_PER_CONTRACT'].map({'Y': 1, 'N': 0}).astype(int)\n",
    "    prev_app['NAME_TYPE_SUITE'].replace('Children', 'Family', inplace=True)\n",
    "    prev_app['NAME_TYPE_SUITE'].replace('Other_A', 'Other', inplace=True)\n",
    "    prev_app['NAME_TYPE_SUITE'].replace('Other_B', 'Other', inplace=True)\n",
    "    prev_app['NAME_TYPE_SUITE'].replace('Group of people', 'Other', inplace=True)\n",
    "    prev_app['NAME_TYPE_SUITE'].replace('Spouse, partner', 'Family', inplace=True)\n",
    "    prev_app['NAME_TYPE_SUITE'].replace('Unaccompanied', 'Single', inplace=True)\n",
    "\n",
    "    prev_app.replace({'NAME_YIELD_GROUP': {'XNA': 0, 'low_action': 1, 'low_normal': 1, 'middle': 3, 'high': 4}}, inplace=True)\n",
    "    prev_app['NAME_YIELD_GROUP'].fillna(0, inplace=True)\n",
    "\n",
    "    def OHE(df, nan_as_category = True):\n",
    "        original_cols = list(df.columns)\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "        # for col in categorical_columns:\n",
    "        #     df[col].fillna('XNA', inplace=True)\n",
    "\n",
    "        df = pd.get_dummies(df, columns= categorical_columns,\n",
    "                            dummy_na= nan_as_category)\n",
    "        new_columns = [c for c in df.columns if c not in original_cols]\n",
    "        return df, new_columns\n",
    "\n",
    "    ## Hung feat\n",
    "    prev_app['ACTIVE'] = prev_app['DAYS_LAST_DUE'] > 0\n",
    "    prev_app['ACTUAL_DURATION'] = prev_app['DAYS_LAST_DUE'] - prev_app['DAYS_FIRST_DUE']\n",
    "    prev_app['DURATION'] = prev_app['DAYS_TERMINATION'] - prev_app['DAYS_FIRST_DUE']\n",
    "    prev_app['LIFETIME_LOAN'] = prev_app['DAYS_TERMINATION'] > 16000\n",
    "\n",
    "    prev_app['FINISH_RATE'] = (prev_app['ACTUAL_DURATION'] / prev_app['DURATION']) * (1 - prev_app['ACTIVE']) * (1 - prev_app['LIFETIME_LOAN'])\n",
    "\n",
    "    # TEST\n",
    "    mask_duration = (prev_app['DURATION'] == 0)\n",
    "    prev_app.loc[mask_duration, 'FINISH_RATE'] = np.nan\n",
    "\n",
    "    #New features from old features\n",
    "\n",
    "    #Ratio: value ask / value received percentage \n",
    "    prev_app = prev_app.drop(prev_app[prev_app['AMT_CREDIT'].isnull() == True].index) \n",
    "    prev_app['AMT_DOWN_PAYMENT'].fillna(0, inplace=True)\n",
    "    prev_app['APP_CREDIT_PERC'] = prev_app['AMT_APPLICATION'] / prev_app['AMT_CREDIT'] * (prev_app['AMT_CREDIT'] != 0)\n",
    "\n",
    "    #dgp\n",
    "    prev_app['DOWN_PAYMENT_RATIO'] = prev_app['AMT_DOWN_PAYMENT']/ prev_app['AMT_CREDIT'] * (prev_app['AMT_CREDIT'] != 0)\n",
    "    prev_app['GOODS_PRICE_RATIO'] = prev_app['AMT_GOODS_PRICE'] / prev_app['AMT_CREDIT'] * (prev_app['AMT_CREDIT'] != 0)\n",
    "\n",
    "\n",
    "    # v1.2\n",
    "    mask_AMT_CREDIT = (prev_app['AMT_CREDIT'] == 0) \n",
    "    prev_app.loc[mask_AMT_CREDIT, 'APP_CREDIT_PERC'] = np.nan\n",
    "    prev_app.loc[mask_AMT_CREDIT, 'DOWN_PAYMENT_RATIO'] = np.nan \n",
    "    prev_app.loc[mask_AMT_CREDIT, 'GOODS_PRICE_RATIO'] = np.nan\n",
    "\n",
    "    # insurance\n",
    "    prev_app['Insuranced_amt_application'] = prev_app['AMT_APPLICATION'] * prev_app['NFLAG_INSURED_ON_APPROVAL']\n",
    "    prev_app['Insuranced_amt_credit'] = prev_app['AMT_CREDIT'] * prev_app['NFLAG_INSURED_ON_APPROVAL']\n",
    "\n",
    "    prev_app['HIGH_AMT_APPLICATION'] = (prev_app['AMT_APPLICATION'] > 100000)\n",
    "    prev_app['Insuranced_high_amt_application'] = prev_app['NFLAG_INSURED_ON_APPROVAL'] * prev_app['HIGH_AMT_APPLICATION']\n",
    "\n",
    "    prev_app['ANNUITY_PAYMENT_PRODUCT'] = prev_app['AMT_ANNUITY'] * prev_app['CNT_PAYMENT']\n",
    "    prev_app['HIGH_DOWN_PAYMENT'] = (prev_app['AMT_DOWN_PAYMENT'] > 10000)\n",
    "\n",
    "    prev_app['CREDIT_DOWNPAYMENT'] = prev_app['AMT_GOODS_PRICE'] - prev_app['AMT_DOWN_PAYMENT']\n",
    "\n",
    "    prev_app['CREDIT_ANNUITY_RATIO'] = prev_app['AMT_CREDIT'] / prev_app['AMT_ANNUITY'] * (prev_app['AMT_ANNUITY'] != 0)\n",
    "    prev_app['RATIO_APPLICATION_TO_ANNUITY'] =  prev_app['AMT_APPLICATION'] / prev_app['AMT_ANNUITY'] * (prev_app['AMT_ANNUITY'] != 0)\n",
    "    prev_app['RATIO_GOODS_TO_ANNUITY'] =  prev_app['AMT_GOODS_PRICE'] / prev_app['AMT_ANNUITY'] * (prev_app['AMT_ANNUITY'] != 0)\n",
    "\n",
    "    # v1.2\n",
    "    mask_AMT_ANNUITY = (prev_app['AMT_ANNUITY'] == 0) \n",
    "    prev_app.loc[mask_AMT_ANNUITY, 'CREDIT_ANNUITY_RATIO'] = np.nan\n",
    "    prev_app.loc[mask_AMT_ANNUITY, 'RATIO_APPLICATION_TO_ANNUITY'] = np.nan\n",
    "    prev_app.loc[mask_AMT_ANNUITY, 'RATIO_GOODS_TO_ANNUITY'] = np.nan\n",
    "\n",
    "    #Churn_prev: Whether the payment date is late \n",
    "    # 1= delayed, 0 = not delayed, NaN = null\n",
    "    k = prev_app.DAYS_LAST_DUE_1ST_VERSION - prev_app.DAYS_LAST_DUE\n",
    "    prev_app[\"CHURN_PREV\"] = [1 if i >= 0 else (0 if i < 0  else \"NaN\") for i in k]\n",
    "\n",
    "    prev_app['AMT_DIFF_PERCENT'] = ((prev_app['AMT_CREDIT'] - prev_app['AMT_APPLICATION']) / prev_app['AMT_APPLICATION']) * 100\n",
    "    prev_app['ADJUSTMENT_DIRECTION'] = (prev_app['AMT_CREDIT'] - prev_app['AMT_APPLICATION']) >= 0\n",
    "    prev_app['ADJUSTMENT_DIRECTION'] = prev_app['ADJUSTMENT_DIRECTION'].map({'True': 1, 'False': 0}) #whether final credit amount is equal clients' application \n",
    "\n",
    "    #Interest rate\n",
    "    prev_app['INTEREST'] = prev_app['CNT_PAYMENT']*prev_app['AMT_ANNUITY'] - prev_app['AMT_CREDIT']\n",
    "    prev_app['INTEREST_RATE'] = 2*12*prev_app['INTEREST']/(prev_app['AMT_CREDIT']*(prev_app['CNT_PAYMENT']+1))\n",
    "    prev_app['INTEREST_SHARE'] = prev_app['INTEREST']/prev_app['AMT_CREDIT']\n",
    "\n",
    "\n",
    "    prev_app[\"DAYS_DECISION\"] = [1 if abs(i/(12*30)) <=1 else 0 for i in prev_app.DAYS_DECISION]\n",
    "\n",
    "    #Separate weekend from weekdays\n",
    "    prev_app[\"WEEKDAY_APPR_PROCESS_START\"] = prev_app[\"WEEKDAY_APPR_PROCESS_START\"].replace(['MONDAY','TUESDAY', 'WEDNESDAY','THURSDAY','FRIDAY'], 'WEEK_DAY')\n",
    "    prev_app[\"WEEKDAY_APPR_PROCESS_START\"] = prev_app[\"WEEKDAY_APPR_PROCESS_START\"].replace(['SATURDAY', 'SUNDAY'], 'WEEKEND')\n",
    "    prev_app[\"WEEKDAY_APPR_PROCESS_START\"].fillna('WEEK_DAY', inplace=True)\n",
    "\n",
    "    #Separate working hours from off_hours\n",
    "    prev_app[\"HOUR_APPR_PROCESS_START\"] = prev_app[\"HOUR_APPR_PROCESS_START\"].replace([8,9,10,11,12,13,14,15,16,17], 'working_hours')\n",
    "    prev_app[\"HOUR_APPR_PROCESS_START\"] = prev_app[\"HOUR_APPR_PROCESS_START\"].replace([18,19,20,21,22,23,0,1,2,3,4,5,6,7], 'off_hours')\n",
    "\n",
    "    prev_app['PRODUCT_COMBINATION'].replace(['XNA', 'POS others without interest'], np.nan, inplace=True)\n",
    "    prev_app['NAME_CONTRACT_TYPE'].replace('XNA', np.nan, inplace=True)\n",
    "    prev_app['NAME_CLIENT_TYPE'].replace('XNA', np.nan, inplace=True)\n",
    "\n",
    "    prev_app['NAME_PAYMENT_TYPE'].replace('Cashless from the account of the employer', np.nan, inplace=True)\n",
    "    prev_app['NAME_GOODS_CATEGORY'].replace(good_replace_2, np.nan, inplace=True)\n",
    "    prev_app['NAME_CASH_LOAN_PURPOSE'].replace(['Everyday expenses', 'Buying a car', 'Repairs'], np.nan, inplace=True)\n",
    "\n",
    "    prev_app['CHANNEL_TYPE'].replace('Car dealer', np.nan, inplace=True)\n",
    "    prev_app['NAME_SELLER_INDUSTRY'].replace(['Tourism', 'Jewelry', 'MLM partners'], np.nan, inplace=True)\n",
    "    prev_app['CODE_REJECT_REASON'].replace(['XNA', 'CLIENT'], np.nan, inplace=True)\n",
    "    prev_app['NAME_PORTFOLIO'].replace('Cars', np.nan, inplace=True)\n",
    "\n",
    "    prev_app, cat_cols = OHE(prev_app, nan_as_category=False)\n",
    "\n",
    "    cat_aggregations = {}\n",
    "    cat_approve_aggegations = {}\n",
    "    for cat in cat_cols:\n",
    "        if 'NAME_CONTRACT' in cat:\n",
    "            \n",
    "            \n",
    "            if 'NAME_CONTRACT_STATUS' not in cat and 'Revolving loans' not in cat:\n",
    "                cat_approve_aggegations[cat] = ['sum']\n",
    "            if 'XNA' in cat:\n",
    "                continue\n",
    "\n",
    "            if 'Unused' in cat:\n",
    "                cat_aggregations[cat] = ['mean']\n",
    "            else:\n",
    "                cat_aggregations[cat] = ['mean', 'sum']\n",
    "\n",
    "        if 'WEEKDAY' in cat or 'HOUR' in cat:\n",
    "            cat_aggregations[cat] = ['mean', 'sum']\n",
    "            cat_approve_aggegations[cat] = ['sum']\n",
    "\n",
    "        if 'CHUN_PREV' in cat:\n",
    "            cat_aggregations[cat] = ['sum', 'mean']\n",
    "            cat_approve_aggegations[cat] = ['sum']\n",
    "        \n",
    "        if 'PURPOSE' in cat:\n",
    "            cat_aggregations[cat] = ['sum']\n",
    "            cat_approve_aggegations[cat] = ['sum']\n",
    "\n",
    "        if 'CODE_REJECT_REASON' in cat:\n",
    "            cat_aggregations[cat] = ['sum']\n",
    "            \n",
    "        if cat not in cat_aggregations:\n",
    "            cat_aggregations[cat] = ['mean']\n",
    "\n",
    "\n",
    "    num_aggregations = {\n",
    "                        'AMT_ANNUITY':             ['sum','min', 'max', 'mean', 'std', 'skew'],\n",
    "                        'AMT_APPLICATION':         ['sum','min', 'max', 'mean', 'std', 'skew'],\n",
    "                        'AMT_CREDIT':              ['sum','min', 'max', 'mean', 'std', 'skew'],\n",
    "                        'APP_CREDIT_PERC':         ['sum','min', 'max', 'mean', 'var', 'skew'],\n",
    "                        'AMT_DOWN_PAYMENT':        [ 'sum','min', 'max', 'mean', 'std', 'skew'],\n",
    "                        'AMT_GOODS_PRICE':         ['sum','min', 'max', 'mean', 'std', 'skew'],\n",
    "                        'CREDIT_ANNUITY_RATIO':    ['mean', 'std' ],\n",
    "\n",
    "                        'DOWN_PAYMENT_RATIO':      ['mean', 'std'],\n",
    "                        'GOODS_PRICE_RATIO':       ['mean', 'std'],\n",
    "                        \n",
    "                        # 'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "                        'RATE_DOWN_PAYMENT':       ['min', 'max', 'mean', 'var'],\n",
    "                        'DAYS_DECISION':           ['max', 'mean', 'var'],\n",
    "                        'CNT_PAYMENT':             ['mean', 'sum'],\n",
    "\n",
    "                        'HIGH_DOWN_PAYMENT':      ['sum'],\n",
    "                        'ANNUITY_PAYMENT_PRODUCT': ['sum', 'mean', 'std', ],\n",
    "                        'RATIO_APPLICATION_TO_ANNUITY': ['mean', 'std'],\n",
    "                        'RATIO_GOODS_TO_ANNUITY': ['mean', 'std'],\n",
    "                        }\n",
    "\n",
    "    num_refuse_aggregations = {\n",
    "                        'AMT_ANNUITY':             ['sum','min', 'max', 'mean', 'std', 'skew'],\n",
    "                        'AMT_APPLICATION':         ['sum','min', 'max', 'mean', 'std', 'skew'],\n",
    "                        'AMT_CREDIT':              ['sum','min', 'max', 'mean', 'std', 'skew'],\n",
    "                        'APP_CREDIT_PERC':         [ 'min', 'max', 'mean', 'var'],\n",
    "                        'AMT_DOWN_PAYMENT':        [ 'sum','min', 'max', 'mean', 'std'],\n",
    "                        'AMT_GOODS_PRICE':         ['sum','min', 'max', 'mean', 'std', 'skew'],\n",
    "                        'CREDIT_ANNUITY_RATIO':    ['mean', 'std' ],\n",
    "                        \n",
    "                        # 'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "                        'RATE_DOWN_PAYMENT':       ['min', 'max', 'mean'],\n",
    "                        'DAYS_DECISION':           [ 'max', 'mean'],\n",
    "                        'CNT_PAYMENT':             ['mean', 'sum'],\n",
    "\n",
    "                        'ANNUITY_PAYMENT_PRODUCT': ['sum', 'mean', 'std', ],\n",
    "                        'RATIO_APPLICATION_TO_ANNUITY': ['mean', 'std'],\n",
    "                            'RATIO_GOODS_TO_ANNUITY': ['mean', 'std'],\n",
    "                            \n",
    "                        }\n",
    "\n",
    "    grouped = prev_app.groupby('SK_ID_CURR')\n",
    "    prev_agg=grouped.agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    prev_agg['PREV_NAME_CONTRACT_STATUS_Refused_SUM'] -= prev_agg['PREV_CODE_REJECT_REASON_SYSTEM_SUM']\n",
    "    prev_agg.drop('PREV_CODE_REJECT_REASON_SYSTEM_SUM', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    num_approve_aggregations = {\n",
    "                        'AMT_ANNUITY':             ['sum', 'min', 'max',  'mean', 'std', 'skew'],\n",
    "                        'AMT_APPLICATION':         ['sum','min', 'max', 'mean', 'std', 'skew'],\n",
    "                        'AMT_CREDIT':              ['sum','min', 'max',  'mean', 'std', 'skew'],\n",
    "                        'APP_CREDIT_PERC':         ['sum','min', 'max', 'mean', 'var', 'skew'],\n",
    "                        'AMT_DOWN_PAYMENT':        ['sum','min', 'max', 'mean', 'std', 'skew'],\n",
    "                        'AMT_GOODS_PRICE':         ['sum','min', 'max', 'mean', 'std',],\n",
    "                        #'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "                        'RATE_DOWN_PAYMENT':       ['min', 'max', 'mean', 'var'],\n",
    "                        'CREDIT_DOWNPAYMENT':      ['sum','min', 'max', 'mean'],\n",
    "\n",
    "                        'DOWN_PAYMENT_RATIO':      ['mean', 'std', 'max'],\n",
    "                        'GOODS_PRICE_RATIO':       ['mean', 'std', 'max'],\n",
    "                        \n",
    "                        'NFLAG_INSURED_ON_APPROVAL' : ['sum'],\n",
    "                        'Insuranced_amt_application' : ['sum', 'mean', 'std'],\n",
    "                        'Insuranced_amt_credit' : ['sum', 'mean', 'std'],\n",
    "                        #  'Insuranced_high_amt_application' : ['sum', 'mean'],\n",
    "                        #  'RATE_INTEREST_PRIMARY':   ['min', 'max', 'mean'],\n",
    "                        #  'RATE_INTEREST_PRIVILEGED':['mean'],\n",
    "                        'DAYS_DECISION':           ['max'],\n",
    "                        'CNT_PAYMENT':             ['mean', 'sum'],\n",
    "                        'ACTIVE':                  [ 'mean'],\n",
    "                        'DURATION':                ['sum', 'max', 'min' ,'mean', 'std', 'skew'],\n",
    "                        'ACTUAL_DURATION':         ['sum', 'max', 'min', 'mean', 'std', 'skew'],\n",
    "                        'LIFETIME_LOAN':           ['sum', 'mean'],\n",
    "                        'FINISH_RATE':             ['mean', 'std'],\n",
    "\n",
    "                        'HIGH_DOWN_PAYMENT':      ['sum'],\n",
    "                        'ANNUITY_PAYMENT_PRODUCT': ['sum', 'mean', 'std', ],\n",
    "                        'RATIO_APPLICATION_TO_ANNUITY': ['mean', 'std'],\n",
    "                        'RATIO_GOODS_TO_ANNUITY': ['mean', 'std'],\n",
    "                        \n",
    "                        }\n",
    "\n",
    "    approved = prev_app[prev_app['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg({**num_approve_aggregations, **cat_approve_aggegations})\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    approved_agg['ratio_amt_application_insuranced'] = approved_agg['APPROVED_Insuranced_amt_application_SUM'] / approved_agg['APPROVED_AMT_APPLICATION_SUM'] * (approved_agg['APPROVED_AMT_APPLICATION_SUM'] != 0)\n",
    "    approved_agg['ratio_amt_credit_insuranced'] = approved_agg['APPROVED_Insuranced_amt_credit_SUM'] / approved_agg['APPROVED_AMT_CREDIT_SUM'] * (approved_agg['APPROVED_AMT_CREDIT_SUM'] != 0)\n",
    "\n",
    "    prev_agg = prev_agg.join(approved_agg,         \n",
    "                            how='left',           \n",
    "                            on='SK_ID_CURR')\n",
    "\n",
    "    refused = prev_app[prev_app['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_refuse_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "\n",
    "    prev_agg = prev_agg.join(                    \n",
    "                            refused_agg,         \n",
    "                            how='left',\n",
    "                            on='SK_ID_CURR'\n",
    "                            )\n",
    "\n",
    "    prev_app = pd.read_csv(os.path.join(ROOT, \"dseb63_previous_application.csv\"))\n",
    "\n",
    "    numbers_of_applications = [1, 3, 5]\n",
    "    features = pd.DataFrame({'SK_ID_CURR': prev_app['SK_ID_CURR'].unique()})\n",
    "    prev_applications_sorted = prev_app.sort_values(['SK_ID_CURR', 'DAYS_DECISION'])\n",
    "    group_object = prev_applications_sorted.groupby(by=['SK_ID_CURR'])['SK_ID_PREV'].nunique().reset_index()\n",
    "    group_object.rename(index=str,\n",
    "                        columns={'SK_ID_PREV': 'previous_application_number_of_prev_application'},\n",
    "                        inplace=True)\n",
    "    features = features.merge(group_object, on=['SK_ID_CURR'], how='left')\n",
    "\n",
    "    prev_applications_sorted['previous_application_prev_was_approved'] = (\n",
    "            prev_applications_sorted['NAME_CONTRACT_STATUS'] == 'Approved').astype('int')\n",
    "    group_object = prev_applications_sorted.groupby(by=['SK_ID_CURR'])[\n",
    "        'previous_application_prev_was_approved'].last().reset_index()\n",
    "    features = features.merge(group_object, on=['SK_ID_CURR'], how='left')\n",
    "\n",
    "    prev_applications_sorted['previous_application_prev_was_refused'] = (\n",
    "            prev_applications_sorted['NAME_CONTRACT_STATUS'] == 'Refused').astype('int')\n",
    "    group_object = prev_applications_sorted.groupby(by=['SK_ID_CURR'])[\n",
    "        'previous_application_prev_was_refused'].last().reset_index()\n",
    "    features = features.merge(group_object, on=['SK_ID_CURR'], how='left')\n",
    "\n",
    "    for number in numbers_of_applications:\n",
    "        prev_applications_tail = prev_applications_sorted.groupby(by=['SK_ID_CURR']).tail(number)\n",
    "\n",
    "        group_object = prev_applications_tail.groupby(by=['SK_ID_CURR'])['CNT_PAYMENT'].mean().reset_index()\n",
    "        group_object.rename(index=str, columns={\n",
    "            'CNT_PAYMENT': 'previous_application_term_of_last_{}_credits_mean'.format(number)},\n",
    "                            inplace=True)\n",
    "        features = features.merge(group_object, on=['SK_ID_CURR'], how='left')\n",
    "\n",
    "        group_object = prev_applications_tail.groupby(by=['SK_ID_CURR'])['DAYS_DECISION'].mean().reset_index()\n",
    "        group_object.rename(index=str, columns={\n",
    "            'DAYS_DECISION': 'previous_application_days_decision_about_last_{}_credits_mean'.format(number)},\n",
    "                            inplace=True)\n",
    "        features = features.merge(group_object, on=['SK_ID_CURR'], how='left')\n",
    "\n",
    "        group_object = prev_applications_tail.groupby(by=['SK_ID_CURR'])['DAYS_FIRST_DRAWING'].mean().reset_index()\n",
    "        group_object.rename(index=str, columns={\n",
    "            'DAYS_FIRST_DRAWING': 'previous_application_days_first_drawing_last_{}_credits_mean'.format(number)},\n",
    "                            inplace=True)\n",
    "        features = features.merge(group_object, on=['SK_ID_CURR'], how='left')\n",
    "        \n",
    "    features.drop(columns=['previous_application_prev_was_approved'], inplace=True)\n",
    "    prev_agg = prev_agg.merge(features, on='SK_ID_CURR', how='left')\n",
    "\n",
    "    return prev_agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:00:26.435203Z",
     "iopub.status.busy": "2024-12-08T11:00:26.434787Z",
     "iopub.status.idle": "2024-12-08T11:00:26.456535Z",
     "shell.execute_reply": "2024-12-08T11:00:26.455337Z",
     "shell.execute_reply.started": "2024-12-08T11:00:26.435162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_bureau_balance():\n",
    "    bureau_balance = pd.read_csv(os.path.join(ROOT, \"dseb63_bureau_balance.csv\"))\n",
    "    bureau_balance['MAX_MONTHS_BALANCE'] = bureau_balance.groupby('SK_ID_BUREAU')['MONTHS_BALANCE'].transform('max')\n",
    "    bureau_balance['TOTAL_MONTHS'] = bureau_balance.groupby('SK_ID_BUREAU')['MONTHS_BALANCE'].transform('count')\n",
    "    bureau_balance['DIFF'] = bureau_balance['MAX_MONTHS_BALANCE'] - bureau_balance['MONTHS_BALANCE']\n",
    "    \n",
    "    bureau_balance_last_12 = bureau_balance[bureau_balance['DIFF'] <= 24]\n",
    "    bureau_balance_last_12['C Last 24 Month'] = np.where(bureau_balance_last_12['STATUS'] == 'C', 1, 0)\n",
    "    bureau_balance_last_12['X Last 24 Month'] = np.where(bureau_balance_last_12['STATUS'] == 'X', 1, 0)\n",
    "    bureau_balance_last_12['0 Last 24 Month'] = np.where(bureau_balance_last_12['STATUS'] == '0', 1, 0)\n",
    "    bureau_balance_last_12['1 Last 24 Month'] = np.where(bureau_balance_last_12['STATUS'] == '1', 1, 0)\n",
    "    bureau_balance_last_12['5 Last 24 Month'] = np.where(bureau_balance_last_12['STATUS'] == '5', 1, 0)\n",
    "\n",
    "    bureau_balance_last_12['2-4 Last 24 Month'] = np.where((bureau_balance_last_12['STATUS'] != 'C') & (bureau_balance_last_12['STATUS'] != 'X') & (bureau_balance_last_12['STATUS'] != '0')&(bureau_balance_last_12['STATUS'] != '1')&(bureau_balance_last_12['STATUS'] != '5'), 1, 0)\n",
    "\n",
    "    gb_bureau_balance_last_12 = bureau_balance_last_12.groupby('SK_ID_BUREAU').agg({ 'C Last 24 Month': 'sum', 'X Last 24 Month': 'sum', '0 Last 24 Month': 'sum', '1 Last 24 Month':'sum', '5 Last 24 Month':'sum', '2-4 Last 24 Month': 'sum' })\n",
    "\n",
    "\n",
    "    gb_max_month = bureau_balance.groupby('SK_ID_BUREAU')['MONTHS_BALANCE'].max()\n",
    "    gb_max_month.rename('MAX_MONTHS_BALANCE', inplace=True)\n",
    "    gb_total_months = bureau_balance.groupby('SK_ID_BUREAU')['MONTHS_BALANCE'].count()\n",
    "    gb_total_months.rename('TOTAL_MONTHS', inplace=True)\n",
    "    gb_C = bureau_balance[bureau_balance['STATUS'] == 'C'].groupby('SK_ID_BUREAU')['STATUS'].count()\n",
    "    gb_C.rename('Ratio C', inplace=True)\n",
    "\n",
    "    gb_X = bureau_balance[bureau_balance['STATUS'] == 'X'].groupby('SK_ID_BUREAU')['STATUS'].count()\n",
    "    gb_X.rename('Ratio X', inplace=True)\n",
    "\n",
    "    gb_0 = bureau_balance[bureau_balance['STATUS'] == '0'].groupby('SK_ID_BUREAU')['STATUS'].count()\n",
    "    gb_0.rename('Ratio 0', inplace=True)\n",
    "\n",
    "    gb_Other = bureau_balance[(bureau_balance['STATUS'] != 'C') & (bureau_balance['STATUS'] != 'X') & (bureau_balance['STATUS'] != '0')].groupby('SK_ID_BUREAU')['STATUS'].count()\n",
    "    gb_Other.rename('Ratio Other', inplace=True)\n",
    "    \n",
    "    gb_bureau_balance = pd.merge(gb_bureau_balance_last_12, gb_max_month, on='SK_ID_BUREAU')\n",
    "    gb_bureau_balance = pd.merge(gb_bureau_balance, gb_total_months, on='SK_ID_BUREAU')\n",
    "    gb_bureau_balance = pd.merge(gb_bureau_balance, gb_C, on='SK_ID_BUREAU')\n",
    "    gb_bureau_balance = pd.merge(gb_bureau_balance, gb_X, on='SK_ID_BUREAU')\n",
    "    gb_bureau_balance = pd.merge(gb_bureau_balance, gb_0, on='SK_ID_BUREAU')\n",
    "    gb_bureau_balance = pd.merge(gb_bureau_balance, gb_Other, on='SK_ID_BUREAU')\n",
    "    gb_bureau_balance = gb_bureau_balance.reset_index()\n",
    "    \n",
    "    return gb_bureau_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:00:26.459320Z",
     "iopub.status.busy": "2024-12-08T11:00:26.458397Z",
     "iopub.status.idle": "2024-12-08T11:00:26.487814Z",
     "shell.execute_reply": "2024-12-08T11:00:26.486231Z",
     "shell.execute_reply.started": "2024-12-08T11:00:26.459256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def bureau_active_close_feat(bureau_active, status = 'ACTIVE'):    \n",
    "    bureau_active[\"LAST_30_DAYS\"] = np.where(bureau_active['DAYS_CREDIT'] >= -30, 1, 0)\n",
    "    bureau_active[\"LAST_60_DAYS\"] = np.where(bureau_active['DAYS_CREDIT'] >= -60, 1, 0)\n",
    "    bureau_active[\"LAST_90_DAYS\"] = np.where(bureau_active['DAYS_CREDIT'] >= -90, 1, 0)\n",
    "    bureau_active[\"LAST_180_DAYS\"] = np.where(bureau_active['DAYS_CREDIT'] >= -180, 1, 0)\n",
    "    bureau_active[\"LAST_365_DAYS\"] = np.where(bureau_active['DAYS_CREDIT'] >= -365, 1, 0)\n",
    "    bureau_active[\"LAST_1000_DAYS\"] = np.where(bureau_active['DAYS_CREDIT'] >= -1000, 1, 0)\n",
    "    \n",
    "    bureau_active[\"NEXT_30_DAYS\"] = np.where(bureau_active['DAYS_CREDIT'] <= 30, 1, 0)\n",
    "    bureau_active[\"NEXT_180_DAYS\"] = np.where(bureau_active['DAYS_CREDIT'] <= 60, 1, 0)\n",
    "    bureau_active[\"LIFE_TIME_CREDIT\"] = np.where(bureau_active['DAYS_CREDIT_ENDDATE'] >= 16000, 1, 0)\n",
    "\n",
    "    gb_bureau_active_count = bureau_active.groupby('SK_ID_CURR').agg({ 'SK_ID_BUREAU':'count', \n",
    "                                                                      'LAST_30_DAYS': 'sum', \n",
    "                                                                      'LAST_60_DAYS': 'sum', \n",
    "                                                                      'LAST_90_DAYS': 'sum', \n",
    "                                                                      'LAST_180_DAYS': 'sum', \n",
    "                                                                      'LAST_365_DAYS': 'sum', \n",
    "                                                                      'LAST_1000_DAYS':'sum', \n",
    "                                                                      'NEXT_30_DAYS': 'sum', \n",
    "                                                                      'NEXT_180_DAYS': 'sum', \n",
    "                                                                      'LIFE_TIME_CREDIT': 'sum', \n",
    "                                                                      'CREDIT_TYPE':'nunique', \n",
    "                                                                      'DAYS_CREDIT': 'max',\n",
    "                                                                      \n",
    "                                                                      'AMT_CREDIT_SUM':'sum', \n",
    "                                                                      'AMT_CREDIT_MEAN':'mean',\n",
    "                                                                      'AMT_CREDIT_SUM_DEBT':'sum',\n",
    "                                                                      \n",
    "                                                                    'AMT_CREDIT_DEBT_MEAN':'mean',\n",
    "                                                                      'AMT_CREDIT_SUM_LIMIT':'sum', \n",
    "                                                                      'AMT_ANNUITY':'sum'}).reset_index()\n",
    "    gb_bureau_active_count.rename(columns={ 'SK_ID_BUREAU':status, 'LAST_30_DAYS':f'{status}_LAST_30_DAYS', 'LAST_60_DAYS':f'{status}_LAST_60_DAYS', 'LAST_90_DAYS':f'{status}_LAST_90_DAYS', 'LAST_180_DAYS':f'{status}_LAST_180_DAYS', 'LAST_365_DAYS':f'{status}_LAST_365_DAYS', 'LAST_1000_DAYS':f'{status}_LAST_1000_DAYS', 'NEXT_30_DAYS':f'{status}_NEXT_30_DAYS', 'NEXT_180_DAYS':f'{status}_NEXT_180_DAYS', 'LIFE_TIME_CREDIT':f'{status}_LIFE_TIME_CREDIT', 'CREDIT_TYPE':f'{status}_CREDIT_TYPE', 'AMT_CREDIT_SUM': f'{status}_AMT_CREDIT_SUM', 'AMT_CREDIT_SUM_LIMIT':f'{status}_AMT_CREDIT_SUM_LIMIT', 'AMT_ANNUITY':f'{status}_AMT_ANNUITY', 'DAYS_CREDIT':f'{status}_DAYS_CREDIT' }, inplace=True)\n",
    "    df_30_days = bureau_active[bureau_active['LAST_30_DAYS'] == 1].copy()\n",
    "    gb_bureau_active_30_days = df_30_days.groupby('SK_ID_CURR').agg({'AMT_CREDIT_SUM': 'sum'}).reset_index()\n",
    "    gb_bureau_active_30_days.rename(columns={'AMT_CREDIT_SUM':f'{status}_SUM_CREDIT_30_DAYS'}, inplace=True)\n",
    "\n",
    "    df_180_days = bureau_active[bureau_active['LAST_180_DAYS'] == 1].copy()\n",
    "    gb_bureau_active_180_days = df_180_days.groupby('SK_ID_CURR').agg({'AMT_CREDIT_SUM': 'sum', 'AMT_CREDIT_SUM_DEBT': 'sum'}).reset_index()\n",
    "    gb_bureau_active_180_days.rename(columns={'AMT_CREDIT_SUM':f'{status}_SUM_CREDIT_180_DAYS', 'AMT_CREDIT_SUM_DEBT':f'{status}_SUM_DEBT_180_DAYS'}, inplace=True)\n",
    "\n",
    "\n",
    "    df_life_time_credit = bureau_active[bureau_active['LIFE_TIME_CREDIT'] == 1].copy()\n",
    "    \n",
    "    if status == 'ACTIVE':\n",
    "        gb_bureau_active_life_time_credit = df_life_time_credit.groupby('SK_ID_CURR').agg({'AMT_CREDIT_SUM': 'sum', 'AMT_CREDIT_SUM_DEBT': 'sum'}).reset_index()\n",
    "        gb_bureau_active_life_time_credit.rename(columns={'AMT_CREDIT_SUM':f'{status}_SUM_CREDIT_LIFE_TIME', 'AMT_CREDIT_SUM_DEBT':f'{status}_SUM_DEBT_LIFE_TIME'}, inplace=True)\n",
    "    else:\n",
    "        gb_bureau_active_life_time_credit = df_life_time_credit.groupby('SK_ID_CURR').agg({'AMT_CREDIT_SUM': 'sum',}).reset_index()\n",
    "        gb_bureau_active_life_time_credit.rename(columns={'AMT_CREDIT_SUM':f'{status}_SUM_CREDIT_LIFE_TIME'}, inplace=True)\n",
    "\n",
    "    df_not_life_time_credit = bureau_active[(bureau_active['LIFE_TIME_CREDIT'] == 0) & (bureau_active['DURATION'] >= 0)].copy()\n",
    "    gb_bureau_active_not_life_time_credit = df_not_life_time_credit.groupby('SK_ID_CURR').agg({'DURATION':'mean'}).reset_index()\n",
    "    gb_bureau_active_not_life_time_credit.rename(columns={'DURATION':f'{status}_MEAN_DURATION_NOT_LIFE_TIME'}, inplace=True)\n",
    "\n",
    "    if status == 'ACTIVE':\n",
    "       \n",
    "        gb_bureau_active_count = pd.merge(gb_bureau_active_count, gb_bureau_active_30_days, on='SK_ID_CURR', how='left')\n",
    "    gb_bureau_active_count = pd.merge(gb_bureau_active_count, gb_bureau_active_180_days, on='SK_ID_CURR', how='left')\n",
    "    gb_bureau_active_count = pd.merge(gb_bureau_active_count, gb_bureau_active_life_time_credit, on='SK_ID_CURR', how='left')\n",
    "    gb_bureau_active_count = pd.merge(gb_bureau_active_count, gb_bureau_active_not_life_time_credit, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    if status == 'CLOSE':\n",
    "        \n",
    "        gb_bureau_active_count.drop(columns=[f'{status}_NEXT_30_DAYS', f'{status}_NEXT_180_DAYS', f'{status}_LAST_30_DAYS', f'{status}_LAST_60_DAYS', f'{status}_SUM_DEBT_180_DAYS'], inplace=True)\n",
    "        \n",
    "        # Add latency here\n",
    "        \n",
    "        # df_not_life_time_credit['LATENCY_30_DAYS'] = df_not_life_time_credit['LATENCY']*df_not_life_time_credit[\"LAST_30_DAYS\"]\n",
    "        df_not_life_time_credit['LATENCY_180_DAYS'] = df_not_life_time_credit['LATENCY']*df_not_life_time_credit[\"LAST_180_DAYS\"]\n",
    "        df_not_life_time_credit['LATENCY_365_DAYS'] = df_not_life_time_credit['LATENCY']*df_not_life_time_credit[\"LAST_365_DAYS\"]\n",
    "        \n",
    "        gb_bureau_active_latency = df_not_life_time_credit.groupby('SK_ID_CURR').agg({'LATENCY_180_DAYS':'sum', 'LATENCY_365_DAYS':'sum', 'LATENCY':'mean'}).reset_index()\n",
    "        gb_bureau_active_latency.rename(columns={'LATENCY_180_DAYS':'CLOSE_LATENCY_180_DAYS', 'LATENCY_365_DAYS':'CLOSE_LATENCY_365_DAYS', 'LATENCY':'CLOSE_MEAN_LATENCY'}, inplace=True)\n",
    "        gb_bureau_active_count = pd.merge(gb_bureau_active_count, gb_bureau_active_latency, on='SK_ID_CURR', how='left')\n",
    "        \n",
    "        gb_bureau_active_count['CLOSE_LATENCY_180_DAYS'] = gb_bureau_active_count['CLOSE_LATENCY_180_DAYS']/gb_bureau_active_count['CLOSE_LAST_180_DAYS']\n",
    "        gb_bureau_active_count['CLOSE_LATENCY_365_DAYS'] = gb_bureau_active_count['CLOSE_LATENCY_365_DAYS']/gb_bureau_active_count['CLOSE_LAST_365_DAYS']\n",
    "        \n",
    "        # Add mask ??\n",
    "    \n",
    "    return gb_bureau_active_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:00:26.490673Z",
     "iopub.status.busy": "2024-12-08T11:00:26.490175Z",
     "iopub.status.idle": "2024-12-08T11:00:26.527477Z",
     "shell.execute_reply": "2024-12-08T11:00:26.525721Z",
     "shell.execute_reply.started": "2024-12-08T11:00:26.490618Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_bureau():\n",
    "    bureau = pd.read_csv(os.path.join(ROOT, \"dseb63_bureau.csv\"))\n",
    "    \n",
    "    bureau['DAYS_CREDIT_ENDDATE'][bureau['DAYS_CREDIT_ENDDATE'] < -40000] = np.nan\n",
    "    bureau['DAYS_CREDIT_UPDATE'][bureau['DAYS_CREDIT_UPDATE'] < -40000] = np.nan\n",
    "    bureau['DAYS_ENDDATE_FACT'][bureau['DAYS_ENDDATE_FACT'] < -40000] = np.nan\n",
    "    \n",
    "    bureau['CREDIT_DURATION'] = bureau['DAYS_CREDIT'] - bureau['DAYS_CREDIT_ENDDATE']\n",
    "    bureau['ENDDATE_DIF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n",
    "    bureau['DEBT_PERCENTAGE'] = bureau['AMT_CREDIT_SUM'] / (bureau['AMT_CREDIT_SUM_DEBT'] + 1)\n",
    "    bureau['DEBT_CREDIT_DIFF'] = bureau['AMT_CREDIT_SUM'] - bureau['AMT_CREDIT_SUM_DEBT']\n",
    "    bureau['CREDIT_TO_ANNUITY_RATIO'] = bureau['AMT_CREDIT_SUM'] / (bureau['AMT_ANNUITY'] + 1)\n",
    "    bureau['BUREAU_CREDIT_DEBT_RATIO'] = bureau['AMT_CREDIT_SUM_DEBT'] / (bureau['AMT_CREDIT_SUM'] + 1) \n",
    "\n",
    "    bureau['UTILIZATION_RATIO'] = bureau['AMT_CREDIT_SUM_DEBT'] / (bureau['AMT_CREDIT_SUM_LIMIT'] +1)\n",
    "    \n",
    "    bureau['DEBT_PERCENTAGE'] *= (bureau['AMT_CREDIT_SUM_DEBT'] !=0)\n",
    "    bureau['CREDIT_TO_ANNUITY_RATIO'] *= (bureau['AMT_ANNUITY'] !=0)\n",
    "    bureau['BUREAU_CREDIT_DEBT_RATIO'] *= (bureau['AMT_CREDIT_SUM'] !=0)\n",
    "    bureau['UTILIZATION_RATIO'] *= (bureau['AMT_CREDIT_SUM_LIMIT'] !=0)\n",
    "\n",
    "    mask_sum_debt = (bureau['AMT_CREDIT_SUM_DEBT'] ==0)\n",
    "    bureau.loc[mask_sum_debt, 'DEBT_PERCENTAGE'] = np.nan\n",
    "\n",
    "    mask_annuity = (bureau['AMT_ANNUITY'] ==0)\n",
    "    bureau.loc[mask_annuity, 'CREDIT_TO_ANNUITY_RATIO'] = np.nan\n",
    "\n",
    "    mask_credit_sum = (bureau['AMT_CREDIT_SUM'] ==0)\n",
    "    bureau.loc[mask_credit_sum, 'BUREAU_CREDIT_DEBT_RATIO'] = np.nan\n",
    "\n",
    "    mask_credit_sum_limit = (bureau['AMT_CREDIT_SUM_LIMIT'] ==0)\n",
    "    bureau.loc[mask_credit_sum_limit, 'UTILIZATION_RATIO'] = np.nan\n",
    "\n",
    "    bureau['DEBT_PERCENTAGE'] = bureau['DEBT_PERCENTAGE'].clip(-9,9)\n",
    "    bureau['CREDIT_TO_ANNUITY_RATIO'] = bureau['CREDIT_TO_ANNUITY_RATIO'].clip(-9,9)\n",
    "    bureau['BUREAU_CREDIT_DEBT_RATIO'] = bureau['BUREAU_CREDIT_DEBT_RATIO'].clip(-9,9)\n",
    "    bureau['UTILIZATION_RATIO'] = bureau['UTILIZATION_RATIO'].clip(-9,9)\n",
    "    bureau['UNPAID_CREDIT'] = np.where(bureau['DAYS_ENDDATE_FACT'].isnull(), 0, 1) \n",
    "    \n",
    "    bureau['AMT_CREDIT_MEAN'] = bureau['AMT_CREDIT_SUM']\n",
    "    bureau['AMT_CREDIT_DEBT_MEAN'] = bureau['AMT_CREDIT_SUM_DEBT']\n",
    "    \n",
    "    gb_bureau_general = bureau.groupby('SK_ID_CURR').agg({'SK_ID_BUREAU': 'count',\n",
    "                                                      'AMT_CREDIT_SUM': ['sum', 'mean', 'std'], \n",
    "                                                      'AMT_CREDIT_SUM_DEBT': ['sum', 'mean', 'std'],  \n",
    "                                                      'AMT_CREDIT_SUM_OVERDUE': ['sum'], \n",
    "                                                      \n",
    "                                                      'AMT_ANNUITY': ['sum', 'mean', 'std'], \n",
    "                                                       \n",
    "                                                       # Check later (v3)\n",
    "                                                      'CNT_CREDIT_PROLONG': [ 'mean'], \n",
    "                                                      'DAYS_CREDIT_UPDATE': ['mean', 'max'],\n",
    "                                                      'CREDIT_DURATION': ['mean', 'std'],\n",
    "                                                      'AMT_CREDIT_MAX_OVERDUE': ['sum', 'mean', 'std'],\n",
    "                                                      'AMT_CREDIT_SUM_LIMIT':['sum', 'mean', 'std'], \n",
    "                                                      \n",
    "                                                      # 'CREDIT_DURATION': 'mean',\n",
    "                                                      # 'AMT_CREDIT_SUM_LIMIT':['mean', 'std'],\n",
    "                                                      \n",
    "                                                      # 'CREDIT_CURRENCY': 'nunique', \n",
    "                                                      'CREDIT_TYPE': 'nunique', \n",
    "                                                      'CREDIT_ACTIVE': 'nunique' ,\n",
    "                                                      \n",
    "\n",
    "\n",
    "                                                      'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "                                                      'ENDDATE_DIF': 'mean',\n",
    "                                                        'DEBT_PERCENTAGE': ['mean','std'],\n",
    "                                                        'DEBT_CREDIT_DIFF': ['mean','std'],\n",
    "\n",
    "                                                          #v3\n",
    "                                                        # 'CREDIT_TO_ANNUITY_RATIO': 'mean',\n",
    "                                                        # 'BUREAU_CREDIT_DEBT_RATIO': 'mean',\n",
    "                                                      \n",
    "                                                      # v3.1\n",
    "                                                      'CREDIT_TO_ANNUITY_RATIO': ['mean', 'var'],\n",
    "                                                      'BUREAU_CREDIT_DEBT_RATIO': ['mean','var'],\n",
    "\n",
    "                                                        'UTILIZATION_RATIO': ['mean', 'std']\n",
    "                                                      }).reset_index()\n",
    "    gb_bureau_general.columns = ['GENERAL_'+'_'.join(col).strip() for col in gb_bureau_general.columns.values]\n",
    "\n",
    "\n",
    "    gb_bureau_general.rename(columns={'GENERAL_SK_ID_CURR_':'SK_ID_CURR'}, inplace=True)\n",
    "\n",
    "    gb_bureau_general['GENERAL_AVG_PAST_LOAN_PER_TYPE'] = gb_bureau_general['GENERAL_CREDIT_TYPE_nunique'] / gb_bureau_general['GENERAL_SK_ID_BUREAU_count'] * (gb_bureau_general['GENERAL_SK_ID_BUREAU_count'] != 0)\n",
    "\n",
    "\n",
    "    others_loan = ['Another type of loan', 'Unknown type of loan', 'Loan for working capital replenishment', 'Cash loan (non-earmarked)', 'Real estate loan', 'Loan for the purchase of equipment', 'Mobile operator loan', 'Interbank credit', 'Loan for purchase of shares (margin lending)']\n",
    "    mapping_others_loan= {x: 'Others' for x in others_loan}\n",
    "    bureau['CREDIT_TYPE'] = bureau['CREDIT_TYPE'].replace(mapping_others_loan)\n",
    "\n",
    "    sum_on_car_loan = bureau[bureau['CREDIT_TYPE'] == 'Car loan'].groupby('SK_ID_CURR').agg({'AMT_CREDIT_SUM': 'sum'}).reset_index()\n",
    "    sum_on_car_loan.rename(columns={'AMT_CREDIT_SUM':'SUM_CREDIT_CAR_LOAN'}, inplace=True)\n",
    "\n",
    "    sum_on_credit_card = bureau[bureau['CREDIT_TYPE'] == 'Credit card'].groupby('SK_ID_CURR').agg({'AMT_CREDIT_SUM': 'sum', 'AMT_CREDIT_SUM_DEBT': 'sum', 'AMT_CREDIT_SUM_OVERDUE': 'sum'}).reset_index()\n",
    "    sum_on_credit_card.rename(columns={'AMT_CREDIT_SUM':'SUM_CREDIT_CARD', 'AMT_CREDIT_SUM_DEBT':'SUM_DEBT_CARD', 'AMT_CREDIT_SUM_OVERDUE':'SUM_OVERDUE_CARD' }, inplace=True)\n",
    "\n",
    "    sum_on_mortgage = bureau[bureau['CREDIT_TYPE'] == 'Mortgage'].groupby('SK_ID_CURR').agg({'AMT_CREDIT_SUM': 'sum', 'AMT_CREDIT_SUM_DEBT': 'sum'}).reset_index()\n",
    "    sum_on_mortgage.rename(columns={'AMT_CREDIT_SUM':'SUM_MORTGAGE', 'AMT_CREDIT_SUM_DEBT':'SUM_DEBT_MORTGAGE' }, inplace=True)\n",
    "\n",
    "    sum_on_consumer_credit = bureau[bureau['CREDIT_TYPE'] == 'Consumer credit'].groupby('SK_ID_CURR').agg({'AMT_CREDIT_SUM': 'sum', 'AMT_CREDIT_SUM_DEBT': 'sum', 'AMT_CREDIT_SUM_OVERDUE': 'sum'}).reset_index()\n",
    "    sum_on_consumer_credit.rename(columns={'AMT_CREDIT_SUM':'SUM_CONSUMER_CREDIT', 'AMT_CREDIT_SUM_DEBT':'SUM_DEBT_CONSUMER_CREDIT', 'AMT_CREDIT_SUM_OVERDUE':'SUM_OVERDUE_CONSUMER_CREDIT' }, inplace=True)\n",
    "\n",
    "    sum_on_microloan = bureau[bureau['CREDIT_TYPE'] == 'Microloan'].groupby('SK_ID_CURR').agg({'AMT_CREDIT_SUM': 'sum', 'AMT_CREDIT_SUM_DEBT': 'sum' }).reset_index()\n",
    "    sum_on_microloan.rename(columns={'AMT_CREDIT_SUM':'SUM_MICROLOAN', 'AMT_CREDIT_SUM_DEBT':'SUM_DEBT_MICROLOAN'}, inplace=True)\n",
    "\n",
    "    gb_bureau_general = pd.merge(gb_bureau_general, sum_on_car_loan, on='SK_ID_CURR', how='left')\n",
    "    gb_bureau_general = pd.merge(gb_bureau_general, sum_on_credit_card, on='SK_ID_CURR', how='left')\n",
    "    gb_bureau_general = pd.merge(gb_bureau_general, sum_on_mortgage, on='SK_ID_CURR', how='left')\n",
    "    gb_bureau_general = pd.merge(gb_bureau_general, sum_on_consumer_credit, on='SK_ID_CURR', how='left')\n",
    "    gb_bureau_general = pd.merge(gb_bureau_general, sum_on_microloan, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    bureau['DAYS_CREDIT_ENDDATE'] = bureau['DAYS_CREDIT_ENDDATE'].fillna(365243)\n",
    "    bureau['DURATION'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_CREDIT']\n",
    "    \n",
    "    bureau_active = bureau[bureau['CREDIT_ACTIVE'] == 'Active']\n",
    "    gb_bureau_active_count = bureau_active_close_feat(bureau_active, 'ACTIVE')\n",
    "    \n",
    "    bureau_closed = bureau[bureau['CREDIT_ACTIVE'] == 'Closed']\n",
    "    bureau_closed = bureau_closed[bureau_closed['DAYS_ENDDATE_FACT'] >= -16000]\n",
    "    bureau_closed['LATENCY'] =  bureau_closed['DAYS_CREDIT_ENDDATE'] - bureau_closed['DAYS_ENDDATE_FACT']\n",
    "    gb_bureau_close_count = bureau_active_close_feat(bureau_closed, 'CLOSE')\n",
    "    bureau_closed.dropna(subset=['DAYS_ENDDATE_FACT'], inplace=True)\n",
    "\n",
    "    bureau_sold = bureau[bureau['CREDIT_ACTIVE'] == 'Sold']\n",
    "    bureau_sold['SOLD_LAST_1000_DAYS'] = np.where(bureau_sold['DAYS_CREDIT'].values >= -1000, 1, 0)\n",
    "\n",
    "    bureau_sold['SOLD_FINISHED'] = np.where(bureau_sold['DAYS_ENDDATE_FACT'].isnull(), 0, 1)\n",
    "    bureau_sold['SOLD_DURATION'] = (bureau_sold['DAYS_ENDDATE_FACT'] - bureau_sold['DAYS_CREDIT']) * bureau_sold['SOLD_FINISHED']\n",
    "\n",
    "    gb_bureau_sold = bureau_sold.groupby('SK_ID_CURR').agg({ 'SOLD_LAST_1000_DAYS': 'sum', 'SOLD_FINISHED': 'sum', 'SOLD_DURATION':'sum'}).reset_index()\n",
    "    gb_bureau_sold['SOLD_DURATION'] = gb_bureau_sold['SOLD_DURATION']/(gb_bureau_sold['SOLD_FINISHED'] + 1e-5)\n",
    "    mask = (gb_bureau_sold['SOLD_FINISHED'] == 0)\n",
    "    gb_bureau_sold['SOLD_DURATION'] *= (gb_bureau_sold['SOLD_FINISHED'] != 0)\n",
    "    gb_bureau_sold['SOLD_DURATION'].loc[mask] = np.nan\n",
    "    \n",
    "    bureau_bad_debt = bureau[bureau['CREDIT_ACTIVE'] == 'Bad debt']\n",
    "    bureau_bad_debt['BAD_DEBT_LAST_5_YEAR'] = np.where(bureau_bad_debt['DAYS_CREDIT'].values >= - 356*5, 1, 0)\n",
    "    bureau_bad_debt['BAD_DEBT_FINISHED'] = np.where(bureau_bad_debt['DAYS_ENDDATE_FACT'].isnull(), 0, 1)\n",
    "    gb_bureau_bad_debt = bureau_bad_debt.groupby('SK_ID_CURR').agg({ 'BAD_DEBT_LAST_5_YEAR': 'sum', 'BAD_DEBT_FINISHED': 'sum'}).reset_index()\n",
    "    gb_bureau_general = pd.merge(gb_bureau_general, gb_bureau_active_count, on='SK_ID_CURR', how='left')\n",
    "    gb_bureau_general = pd.merge(gb_bureau_general, gb_bureau_close_count, on='SK_ID_CURR', how='left')\n",
    "    gb_bureau_general = pd.merge(gb_bureau_general, gb_bureau_sold, on='SK_ID_CURR', how='left')\n",
    "    gb_bureau_general = pd.merge(gb_bureau_general, gb_bureau_bad_debt, on='SK_ID_CURR', how='left')\n",
    "\n",
    "    bureau_balance = process_bureau_balance()\n",
    "    bureau_balance = pd.merge(bureau_balance, bureau[['SK_ID_CURR', 'SK_ID_BUREAU']], on='SK_ID_BUREAU', how='left')\n",
    "    bureau_balance.dropna(subset=['SK_ID_CURR'], inplace=True)\n",
    "    gb_bureau_balance = bureau_balance.groupby('SK_ID_CURR').agg({'0 Last 24 Month':'sum', 'TOTAL_MONTHS':'sum', 'Ratio C':'sum' , 'Ratio X':'sum', 'Ratio 0':'sum', 'Ratio Other': 'sum'}).reset_index()\n",
    "    gb_bureau_balance['Ratio C'] = gb_bureau_balance['Ratio C']/gb_bureau_balance['TOTAL_MONTHS'] * (gb_bureau_balance['TOTAL_MONTHS'] != 0)\n",
    "    gb_bureau_balance['Ratio X'] = gb_bureau_balance['Ratio X']/gb_bureau_balance['TOTAL_MONTHS'] * (gb_bureau_balance['TOTAL_MONTHS'] != 0)\n",
    "    gb_bureau_balance['Ratio 0'] = gb_bureau_balance['Ratio 0']/gb_bureau_balance['TOTAL_MONTHS'] * (gb_bureau_balance['TOTAL_MONTHS'] != 0)\n",
    "    gb_bureau_balance['Ratio Other'] = gb_bureau_balance['Ratio Other']/gb_bureau_balance['TOTAL_MONTHS'] * (gb_bureau_balance['TOTAL_MONTHS'] != 0)\n",
    "\n",
    "    gb_bureau_balance.drop(columns=['TOTAL_MONTHS'], inplace=True)\n",
    "    gb_bureau_general = pd.merge(gb_bureau_general, gb_bureau_balance, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    \n",
    "    gb_bureau_general['DEBT_CREDIT_RATIO'] = gb_bureau_general['GENERAL_AMT_CREDIT_SUM_DEBT_sum'] / (gb_bureau_general['GENERAL_AMT_CREDIT_SUM_sum'] + 1e-5) * (gb_bureau_general['GENERAL_AMT_CREDIT_SUM_sum'] != 0)\n",
    "    mask = (gb_bureau_general['GENERAL_AMT_CREDIT_SUM_sum'] == 0)\n",
    "    gb_bureau_general['DEBT_CREDIT_RATIO'].loc[mask] = np.nan\n",
    "    \n",
    "    return gb_bureau_general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:00:26.529640Z",
     "iopub.status.busy": "2024-12-08T11:00:26.529249Z",
     "iopub.status.idle": "2024-12-08T11:00:26.569504Z",
     "shell.execute_reply": "2024-12-08T11:00:26.567585Z",
     "shell.execute_reply.started": "2024-12-08T11:00:26.529603Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_credit_card_balance():\n",
    "    balance = pd.read_csv(os.path.join(ROOT, \"dseb63_credit_card_balance.csv\"))\n",
    "    balance['AMT_DRAWINGS_ATM_CURRENT'][balance['AMT_DRAWINGS_ATM_CURRENT'] < 0] = np.nan\n",
    "    balance['AMT_DRAWINGS_CURRENT'][balance['AMT_DRAWINGS_CURRENT'] < 0] = np.nan\n",
    "    balance[\"ACTIVE\"] = balance[\"NAME_CONTRACT_STATUS\"].apply(lambda x: 1 if x == \"Active\" else 0)\n",
    "    balance[\"COMPLETED\"] = balance[\"NAME_CONTRACT_STATUS\"].apply(lambda x: 1 if x == \"Completed\" else 0)\n",
    "    balance[\"DEMAND\"] = balance[\"NAME_CONTRACT_STATUS\"].apply(lambda x: 1 if x == \"Demand\" else 0)\n",
    "    balance[\"REFUSED\"] = balance[\"NAME_CONTRACT_STATUS\"].apply(lambda x: 1 if x == \"Refused\" else 0)\n",
    "    balance[\"SENT_PROPOSAL\"] = balance[\"NAME_CONTRACT_STATUS\"].apply(lambda x: 1 if x == \"Sent proposal\" else 0)\n",
    "    balance[\"SIGNED\"] = balance[\"NAME_CONTRACT_STATUS\"].apply(lambda x: 1 if x == \"Signed\" else 0)\n",
    "    balance['UTILIZATION'] = balance['AMT_BALANCE'] / (balance['AMT_CREDIT_LIMIT_ACTUAL'] + 1e-6)\n",
    "\n",
    "    # v1.2\n",
    "    mask = (balance['AMT_CREDIT_LIMIT_ACTUAL'] == 0)\n",
    "    balance.loc[mask, 'UTILIZATION'] = np.nan\n",
    "\n",
    "    balance['RATE_OF_PAYBACK'] = balance['AMT_PAYMENT_TOTAL_CURRENT'] / (balance['AMT_INST_MIN_REGULARITY'] + 1e-6) * (balance['AMT_INST_MIN_REGULARITY']!=0)\n",
    "    balance['PERCENTAGE_OF_MINIMUM_PAYMENTS_MISSED'] = balance['AMT_PAYMENT_CURRENT'] / (balance['AMT_INST_MIN_REGULARITY'] + 1e-6) *  (balance['AMT_INST_MIN_REGULARITY']!=0)\n",
    "\n",
    "    # v1.2\n",
    "    mask = (balance['AMT_INST_MIN_REGULARITY'] == 0)\n",
    "    balance.loc[mask, 'PERCENTAGE_OF_MINIMUM_PAYMENTS_MISSED'] = np.nan\n",
    "    balance.loc[mask, 'RATE_OF_PAYBACK'] = np.nan # v1.2.1\n",
    "\n",
    "    balance['Change_in_Credit_Limit'] = balance['AMT_CREDIT_LIMIT_ACTUAL'] - balance['AMT_CREDIT_LIMIT_ACTUAL'].shift(1)\n",
    "    balance['Change_in_spending'] = balance['AMT_BALANCE'] - balance['AMT_BALANCE'].shift(1)\n",
    "\n",
    "    balance['MINIMUM_PAYMENTS_ONLY'] = balance['AMT_PAYMENT_CURRENT'] == balance['AMT_INST_MIN_REGULARITY']\n",
    "    balance['RAPID_ACCOUNT_TURNOVER'] = balance['CNT_DRAWINGS_CURRENT'] > balance['CNT_DRAWINGS_CURRENT'].shift(1)\n",
    "\n",
    "    balance['SUM_ALL_CNT_DRAWINGS'] = balance['CNT_DRAWINGS_ATM_CURRENT'] + balance['CNT_DRAWINGS_CURRENT'] + balance['CNT_DRAWINGS_OTHER_CURRENT'] + balance['CNT_DRAWINGS_POS_CURRENT']\n",
    "    balance['SUM_ALL_AMT_DRAWINGS'] = balance['AMT_DRAWINGS_ATM_CURRENT'] + balance['AMT_DRAWINGS_CURRENT'] + balance['AMT_DRAWINGS_OTHER_CURRENT'] + balance['AMT_DRAWINGS_POS_CURRENT']\n",
    "    balance['RATIO_ALL_AMT_DRAWINGS_TO_ALL_CNT_DRAWINGS'] = balance['SUM_ALL_AMT_DRAWINGS'] / (balance['SUM_ALL_CNT_DRAWINGS'] + 1e-6) * (balance['SUM_ALL_CNT_DRAWINGS'] != 0)\n",
    "\n",
    "    # v1.2\n",
    "    mask = (balance['SUM_ALL_CNT_DRAWINGS'] == 0)\n",
    "    balance.loc[mask, 'RATIO_ALL_AMT_DRAWINGS_TO_ALL_CNT_DRAWINGS'] = np.nan\n",
    "    balance['RATIO_ALL_AMT_DRAWINGS_TO_ALL_CNT_DRAWINGS'] = balance['RATIO_ALL_AMT_DRAWINGS_TO_ALL_CNT_DRAWINGS'].clip(-9, 9)\n",
    "\n",
    "    balance['UTILIZATION'] = balance['UTILIZATION'].clip(-9, 9) # v1.2 99->9\n",
    "    balance['RATE_OF_PAYBACK'] = balance['RATE_OF_PAYBACK'].clip(-9, 9)\n",
    "    balance['PERCENTAGE_OF_MINIMUM_PAYMENTS_MISSED'] = balance['PERCENTAGE_OF_MINIMUM_PAYMENTS_MISSED'].clip(-9, 9)\n",
    "    balance[\"POSITIVE_CREDIT\"] = np.where(balance[\"AMT_BALANCE\"] > 0, 1, 0)\n",
    "\n",
    "    balance[\"FLAG_6_MONTHS\"] = np.where(balance[\"MONTHS_BALANCE\"] >= -6, 1, 0)\n",
    "    balance[\"FLAG_12_MONTHS\"] = np.where(balance[\"MONTHS_BALANCE\"] >= -12, 1, 0)\n",
    "    balance[\"FLAG_36_MONTHS\"] = np.where(balance[\"MONTHS_BALANCE\"] >= -36, 1, 0)\n",
    "\n",
    "    balance[\"FLAG_UTILIZATION_LESS_25\"] = np.where(balance[\"UTILIZATION\"] < 0.25, 1, 0)\n",
    "    balance[\"FLAG_UTILIZATION_LESS_50\"] = np.where(balance[\"UTILIZATION\"] < 0.50, 1, 0)\n",
    "    balance[\"FLAG_UTILIZATION_LESS_75\"] = np.where(balance[\"UTILIZATION\"] < 0.75, 1, 0)\n",
    "    balance[\"FLAG_UTILIZATION_LESS_100\"] = np.where(balance[\"UTILIZATION\"] < 1.00, 1, 0)\n",
    "    balance[\"FLAG_UTILIZATION_MORE_100\"] = np.where(balance[\"UTILIZATION\"] > 1.00, 1, 0)\n",
    "\n",
    "    balance['PRINCIPIAL_RATE'] = balance['AMT_RECEIVABLE_PRINCIPAL'] / (balance['AMT_TOTAL_RECEIVABLE'] + 1e-6)\n",
    "    mask = (balance['AMT_TOTAL_RECEIVABLE'] == 0)\n",
    "    balance.loc[mask, 'PRINCIPIAL_RATE'] = np.nan\n",
    "    balance['PRINCIPIAL_RATE'] = balance['PRINCIPIAL_RATE'].clip(-9, 9) #v1.1: 0 -> 99\n",
    "\n",
    "\n",
    "    gb_balance = balance.groupby('SK_ID_CURR').agg({\n",
    "        'MONTHS_BALANCE': ['count'],\n",
    "        'ACTIVE': 'sum',\n",
    "        # 'COMPLETED': 'sum',\n",
    "        # 'DEMAND': 'sum',\n",
    "        # 'REFUSED': 'sum',\n",
    "        # 'SENT_PROPOSAL': 'sum',\n",
    "        'AMT_BALANCE': 'sum', # Divide later\n",
    "        'AMT_CREDIT_LIMIT_ACTUAL': ['mean', 'max', 'min', 'nunique', 'std', 'skew'],\n",
    "        'AMT_INST_MIN_REGULARITY': ['mean', 'max', 'nunique', 'skew'],\n",
    "        'AMT_PAYMENT_TOTAL_CURRENT': ['sum', 'mean', 'max', 'min' , 'std', 'skew'],\n",
    "        \n",
    "        'UTILIZATION' : 'sum', # Divide later\n",
    "        'FLAG_UTILIZATION_LESS_25' : ['sum', 'mean'],\n",
    "        'FLAG_UTILIZATION_LESS_50' : ['sum', 'mean'],\n",
    "        'FLAG_UTILIZATION_LESS_75' : ['sum', 'mean'],\n",
    "        'FLAG_UTILIZATION_LESS_100' : ['sum', 'mean'],\n",
    "        'FLAG_UTILIZATION_MORE_100' : ['sum', 'mean'],\n",
    "        \n",
    "        'CNT_DRAWINGS_ATM_CURRENT' : ['mean', 'sum'],\n",
    "        'CNT_DRAWINGS_CURRENT' : ['mean', 'sum'],\n",
    "        \n",
    "        'AMT_DRAWINGS_ATM_CURRENT' : ['sum', 'mean', 'max', 'std'],\n",
    "        'AMT_DRAWINGS_CURRENT' : ['sum', 'mean', 'max', 'std'],\n",
    "        'AMT_DRAWINGS_POS_CURRENT' : ['sum', 'mean', 'max', 'std'],\n",
    "        'AMT_RECEIVABLE_PRINCIPAL' : 'sum', # Divide later\n",
    "        'PRINCIPIAL_RATE': 'sum', # Divide later\n",
    "        # 'SK_DPD': 'sum',\n",
    "        # 'SK_DPD_DEF': 'sum',\n",
    "        'POSITIVE_CREDIT': 'sum',\n",
    "\n",
    "        'MINIMUM_PAYMENTS_ONLY' : 'sum',\n",
    "        'SUM_ALL_CNT_DRAWINGS' : ['sum', 'mean'],\n",
    "        'SUM_ALL_AMT_DRAWINGS' : ['sum', 'mean'],\n",
    "        'RAPID_ACCOUNT_TURNOVER' : ['sum', 'mean'],\n",
    "        'RATIO_ALL_AMT_DRAWINGS_TO_ALL_CNT_DRAWINGS' : ['mean', 'std'],\n",
    "        \n",
    "        'RATE_OF_PAYBACK': 'sum', # Divide later\n",
    "        'PERCENTAGE_OF_MINIMUM_PAYMENTS_MISSED': 'sum', # Divide later\n",
    "        'Change_in_Credit_Limit': 'sum',\n",
    "        'Change_in_spending': ['sum', 'mean', 'std'],\n",
    "        \n",
    "    }).reset_index()\n",
    "\n",
    "    gb_balance.columns = ['_'.join(col).strip() for col in gb_balance.columns.values]\n",
    "    gb_balance.rename(columns={'SK_ID_CURR_': 'SK_ID_CURR'}, inplace=True)\n",
    "\n",
    "    gb_balance['AMT_BALANCE_sum'] = gb_balance['AMT_BALANCE_sum'] / (gb_balance['POSITIVE_CREDIT_sum']+1)\n",
    "    gb_balance['UTILIZATION_sum'] = gb_balance['UTILIZATION_sum'] / (gb_balance['POSITIVE_CREDIT_sum']+1)\n",
    "    gb_balance['AMT_RECEIVABLE_PRINCIPAL_sum'] = gb_balance['AMT_RECEIVABLE_PRINCIPAL_sum'] / (gb_balance['POSITIVE_CREDIT_sum']+1)\n",
    "    gb_balance['PRINCIPIAL_RATE_sum'] = gb_balance['PRINCIPIAL_RATE_sum'] / (gb_balance['POSITIVE_CREDIT_sum']+1)\n",
    "    gb_balance['RATE_OF_PAYBACK_sum'] = gb_balance['RATE_OF_PAYBACK_sum'] / (gb_balance['POSITIVE_CREDIT_sum']+1)\n",
    "    gb_balance['PERCENTAGE_OF_MINIMUM_PAYMENTS_MISSED_sum'] = gb_balance['PERCENTAGE_OF_MINIMUM_PAYMENTS_MISSED_sum'] / (gb_balance['POSITIVE_CREDIT_sum']+1)\n",
    "    gb_balance['POSITIVE_PERCENT'] = gb_balance['POSITIVE_CREDIT_sum'] / gb_balance['MONTHS_BALANCE_count']\n",
    "\n",
    "    balance_6_months = balance[balance['FLAG_6_MONTHS'] ==1]\n",
    "    balance_12_months = balance[balance['FLAG_12_MONTHS'] ==1]\n",
    "    balance_36_months = balance[balance['FLAG_36_MONTHS'] ==1]\n",
    "\n",
    "    gb_balance_6_months = balance_6_months.groupby('SK_ID_CURR').agg({\n",
    "\n",
    "        'RATE_OF_PAYBACK' : ['mean', 'std'],\n",
    "        'AMT_BALANCE': 'sum', # Divide later\n",
    "        'AMT_CREDIT_LIMIT_ACTUAL': ['mean', 'std'],\n",
    "            'AMT_INST_MIN_REGULARITY': ['mean', 'std'],\n",
    "        'AMT_PAYMENT_TOTAL_CURRENT': 'sum',\n",
    "        \n",
    "        'UTILIZATION' : 'sum', # Divide later\n",
    "        'FLAG_UTILIZATION_LESS_50' : ['sum' ,'mean'],\n",
    "        'FLAG_UTILIZATION_LESS_100' : 'sum',\n",
    "        \n",
    "        'CNT_DRAWINGS_ATM_CURRENT' :  'sum',\n",
    "        'CNT_DRAWINGS_CURRENT' : 'sum',   \n",
    "        'AMT_DRAWINGS_CURRENT' : ['sum', 'max'],\n",
    "        'AMT_RECEIVABLE_PRINCIPAL' : ['sum', 'mean','std'], # Divide later\n",
    "        'PRINCIPIAL_RATE' : [ 'mean', 'std'], # Divide later\n",
    "        'POSITIVE_CREDIT': ['sum']\n",
    "    }).reset_index()\n",
    "\n",
    "    gb_balance_6_months.columns = ['6_MONTH_'+'_'.join(col).strip() for col in gb_balance_6_months.columns.values]\n",
    "    gb_balance_6_months['6_MONTH_AMT_BALANCE_sum'] = gb_balance_6_months['6_MONTH_AMT_BALANCE_sum'] / (gb_balance_6_months['6_MONTH_POSITIVE_CREDIT_sum']+1e-6)\n",
    "    gb_balance_6_months['6_MONTH_UTILIZATION_sum'] = gb_balance_6_months['6_MONTH_UTILIZATION_sum'] / (gb_balance_6_months['6_MONTH_POSITIVE_CREDIT_sum']+1e-6)\n",
    "    gb_balance_6_months['6_MONTH_POSITIVE_CREDIT_mean'] = gb_balance_6_months['6_MONTH_POSITIVE_CREDIT_sum']/6\n",
    "\n",
    "    gb_balance_6_months.drop(columns=['6_MONTH_POSITIVE_CREDIT_sum'], inplace=True)\n",
    "    gb_balance_6_months.rename(columns={'6_MONTH_SK_ID_CURR_':'SK_ID_CURR'}, inplace=True)\n",
    "\n",
    "    gb_balance_12_months = balance_12_months.groupby('SK_ID_CURR').agg({\n",
    "        \n",
    "            'RATE_OF_PAYBACK' : ['mean', 'std'],\n",
    "        'AMT_BALANCE': 'sum', # Divide later\n",
    "        'AMT_CREDIT_LIMIT_ACTUAL': ['mean', 'max', 'min', 'std'],\n",
    "        'AMT_INST_MIN_REGULARITY': ['mean', 'max',  'std'],\n",
    "        'AMT_PAYMENT_TOTAL_CURRENT': ['sum', 'mean', 'std'],\n",
    "        \n",
    "        'UTILIZATION' : 'sum', # Divide later\n",
    "        'FLAG_UTILIZATION_LESS_50' : 'sum',\n",
    "        'FLAG_UTILIZATION_LESS_100' : 'sum',\n",
    "        \n",
    "        'CNT_DRAWINGS_ATM_CURRENT' :  'sum',\n",
    "        'CNT_DRAWINGS_CURRENT' : 'sum',   \n",
    "        'AMT_DRAWINGS_CURRENT' : ['sum', 'max'],\n",
    "\n",
    "    'AMT_RECEIVABLE_PRINCIPAL' : ['sum', 'mean','std'], # Divide later\n",
    "    'PRINCIPIAL_RATE' : [ 'mean', 'std', 'max'],\n",
    "        'POSITIVE_CREDIT': 'sum',\n",
    "        }).reset_index()\n",
    "\n",
    "    gb_balance_12_months.columns = ['12_MONTH_'+'_'.join(col).strip() for col in gb_balance_12_months.columns.values]\n",
    "    gb_balance_12_months['12_MONTH_AMT_BALANCE_sum'] = gb_balance_12_months['12_MONTH_AMT_BALANCE_sum'] / (gb_balance_12_months['12_MONTH_POSITIVE_CREDIT_sum']+1e-6)\n",
    "    gb_balance_12_months['12_MONTH_UTILIZATION_sum'] = gb_balance_12_months['12_MONTH_UTILIZATION_sum'] / (gb_balance_12_months['12_MONTH_POSITIVE_CREDIT_sum']+1e-6)\n",
    "    gb_balance_12_months.rename(columns={'12_MONTH_SK_ID_CURR_':'SK_ID_CURR'}, inplace=True)\n",
    "    gb_balance_12_months['12_MONTH_POSITIVE_CREDIT_mean'] = gb_balance_12_months['12_MONTH_POSITIVE_CREDIT_sum']/12\n",
    "\n",
    "    gb_balance_36_months = balance_36_months.groupby('SK_ID_CURR').agg({\n",
    "            \n",
    "                'AMT_BALANCE': 'sum', # Divide later\n",
    "            'AMT_CREDIT_LIMIT_ACTUAL': ['mean', 'std'],\n",
    "            'AMT_INST_MIN_REGULARITY': ['mean', 'std'],\n",
    "            'AMT_PAYMENT_TOTAL_CURRENT': ['sum', 'mean',  'std', 'skew'],\n",
    "            \n",
    "            'UTILIZATION' : 'sum', # Divide later\n",
    "            'FLAG_UTILIZATION_LESS_50' : 'sum',\n",
    "            'FLAG_UTILIZATION_LESS_100' : 'sum',\n",
    "            \n",
    "            'CNT_DRAWINGS_ATM_CURRENT' :  'sum',\n",
    "            'CNT_DRAWINGS_CURRENT' : 'sum',   \n",
    "            'AMT_DRAWINGS_CURRENT' : ['sum', 'mean', 'max'],\n",
    "        \n",
    "            'POSITIVE_CREDIT': 'sum',\n",
    "            'AMT_RECEIVABLE_PRINCIPAL' : ['sum', 'mean','std'], # Divide later\n",
    "        }).reset_index()\n",
    "\n",
    "    gb_balance_36_months.columns = ['36_MONTH_'+'_'.join(col).strip() for col in gb_balance_36_months.columns.values]\n",
    "    gb_balance_36_months['36_MONTH_AMT_BALANCE_sum'] = gb_balance_36_months['36_MONTH_AMT_BALANCE_sum'] / (gb_balance_36_months['36_MONTH_POSITIVE_CREDIT_sum']+1e-6)\n",
    "    gb_balance_36_months['36_MONTH_UTILIZATION_sum'] = gb_balance_36_months['36_MONTH_UTILIZATION_sum'] / (gb_balance_36_months['36_MONTH_POSITIVE_CREDIT_sum']+1e-6)\n",
    "    gb_balance_36_months.rename(columns={'36_MONTH_SK_ID_CURR_':'SK_ID_CURR'}, inplace=True)\n",
    "    gb_balance_36_months['36_MONTH_POSITIVE_CREDIT_mean'] = gb_balance_36_months['36_MONTH_POSITIVE_CREDIT_sum']/36\n",
    "\n",
    "    gb_balance = pd.merge(gb_balance, gb_balance_6_months, on='SK_ID_CURR', how='left')\n",
    "    gb_balance = pd.merge(gb_balance, gb_balance_12_months, on='SK_ID_CURR', how='left')\n",
    "    gb_balance = pd.merge(gb_balance, gb_balance_36_months, on='SK_ID_CURR', how='left')\n",
    "\n",
    "    return gb_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS CASH Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:00:26.571995Z",
     "iopub.status.busy": "2024-12-08T11:00:26.571486Z",
     "iopub.status.idle": "2024-12-08T11:00:26.593784Z",
     "shell.execute_reply": "2024-12-08T11:00:26.592448Z",
     "shell.execute_reply.started": "2024-12-08T11:00:26.571944Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_pos_cash_balance():\n",
    "    pos_cash = pd.read_csv(os.path.join(ROOT, \"dseb63_POS_CASH_balance.csv\"))\n",
    "    pos_cash = pos_cash[pos_cash['NAME_CONTRACT_STATUS'] != 'XNA']\n",
    "    pos_cash = pos_cash[pos_cash['NAME_CONTRACT_STATUS'] != 'Canceled']\n",
    "    \n",
    "    pos_cash['COMPLETED'] = pos_cash['NAME_CONTRACT_STATUS'] == 'Completed'\n",
    "    pos_cash['COUNT_DEMAND'] = pos_cash['NAME_CONTRACT_STATUS'] == 'Demand'\n",
    "    pos_cash['COUNT_SIGNED'] = pos_cash['NAME_CONTRACT_STATUS'] == 'Signed'\n",
    "    pos_cash['COUNT_APPROVED'] = pos_cash['NAME_CONTRACT_STATUS'] == 'Approved'\n",
    "    pos_cash['COUNT_RETURNED'] = pos_cash['NAME_CONTRACT_STATUS'] == 'Returned to the store'\n",
    "\n",
    "    pos_cash['LAST_3_MONTHS'] = pos_cash['MONTHS_BALANCE'] >= -3\n",
    "    pos_cash['LAST_6_MONTHS'] = pos_cash['MONTHS_BALANCE'] >= -6\n",
    "    pos_cash['LAST_12_MONTHS'] = pos_cash['MONTHS_BALANCE'] >= -12\n",
    "    pos_cash['LAST_36_MONTHS'] = pos_cash['MONTHS_BALANCE'] >= -36\n",
    "\n",
    "    pos_cash['NUM_INSTALMENT'] = 1\n",
    "\n",
    "    pos_cash['COUNT_SK_DPD'] = pos_cash['SK_DPD'] > 0\n",
    "    pos_cash['COUNT_SK_DPD_DEF'] = pos_cash['SK_DPD_DEF'] > 0\n",
    "\n",
    "    pos_cash['MEAN_SK_DPD'] = pos_cash['SK_DPD']\n",
    "    pos_cash['MEAN_SK_DPD_DEF'] = pos_cash['SK_DPD_DEF']\n",
    "\n",
    "    gb_pos_cash = pos_cash.groupby('SK_ID_PREV').agg({\n",
    "        'SK_ID_CURR': 'first',\n",
    "        'NUM_INSTALMENT': 'sum',\n",
    "        'COMPLETED': 'sum',\n",
    "        'COUNT_DEMAND': 'sum',\n",
    "        'COUNT_SIGNED': 'sum',\n",
    "        'COUNT_APPROVED': 'sum',\n",
    "        'COUNT_RETURNED': 'sum',\n",
    "        'CNT_INSTALMENT': 'max',\n",
    "        'MONTHS_BALANCE': 'max',\n",
    "        \n",
    "        'COUNT_SK_DPD':'sum',\n",
    "        'COUNT_SK_DPD_DEF':'sum',\n",
    "        \n",
    "        'SK_DPD':'sum',\n",
    "        'SK_DPD_DEF':'sum',\n",
    "        \n",
    "        'MEAN_SK_DPD':'mean',\n",
    "        'MEAN_SK_DPD_DEF':'mean',\n",
    "        \n",
    "        'CNT_INSTALMENT_FUTURE':'min',\n",
    "        'LAST_3_MONTHS':'sum',\n",
    "        'LAST_6_MONTHS':'sum',\n",
    "        'LAST_12_MONTHS':'sum',\n",
    "        'LAST_36_MONTHS':'sum',\n",
    "    }).reset_index()\n",
    "\n",
    "    gb_pos_cash['LONG_TERM'] = gb_pos_cash['CNT_INSTALMENT'] > 24\n",
    "    gb_pos_cash['SHORT_TERM'] = gb_pos_cash['CNT_INSTALMENT'] <= 24\n",
    "        \n",
    "    gb_pos_cash_by_curr = gb_pos_cash.groupby('SK_ID_CURR').agg({\n",
    "        'NUM_INSTALMENT': 'sum',\n",
    "        'COMPLETED': ['sum', 'mean'],\n",
    "        # 'COUNT_DEMAND': 'sum',\n",
    "        'COUNT_SIGNED': 'sum',\n",
    "        # 'COUNT_APPROVED': ['sum', 'mean'],\n",
    "        # 'COUNT_RETURNED': 'sum',\n",
    "        'CNT_INSTALMENT': ['sum', 'mean', 'var'],\n",
    "        'MONTHS_BALANCE': 'max',\n",
    "        \n",
    "        'SK_DPD':['sum', 'mean', 'max', 'var'],\n",
    "        'SK_DPD_DEF':['sum', 'mean', 'max', 'var'],\n",
    "        \n",
    "        'COUNT_SK_DPD':['sum', 'max', 'mean', 'var'],\n",
    "        'COUNT_SK_DPD_DEF':['sum', 'max', 'mean', 'var'],\n",
    "        \n",
    "        'MEAN_SK_DPD':['sum', 'mean', 'max', 'var'],\n",
    "        'MEAN_SK_DPD_DEF':['sum', 'mean', 'max', 'var'],\n",
    "        \n",
    "        'CNT_INSTALMENT_FUTURE':'sum',\n",
    "        \n",
    "        'LAST_3_MONTHS':'sum',\n",
    "        'LAST_6_MONTHS':'sum',\n",
    "        'LAST_12_MONTHS':'sum',\n",
    "        'LAST_36_MONTHS':'sum',\n",
    "    }).reset_index()\n",
    "\n",
    "    gb_pos_cash_by_curr.columns = ['GENERAL_'+'_'.join(col).strip() for col in gb_pos_cash_by_curr.columns.values]\n",
    "    gb_pos_cash_by_curr.rename(columns={'GENERAL_SK_ID_CURR_':'SK_ID_CURR'}, inplace=True)\n",
    "\n",
    "    gb_pos_cash_complete = gb_pos_cash[gb_pos_cash['COMPLETED'] > 0]\n",
    "    gb_pos_cash_not_complete = gb_pos_cash[gb_pos_cash['COMPLETED'] == 0]\n",
    "    gb_pos_cash_complete['RATE_COMPLETED'] = gb_pos_cash_complete['CNT_INSTALMENT'] / gb_pos_cash_complete['NUM_INSTALMENT']\n",
    "\n",
    "    gb_pos_cash_complete_long_term = gb_pos_cash_complete[gb_pos_cash_complete['LONG_TERM'] == 1]\n",
    "    gb_pos_cash_complete_short_term = gb_pos_cash_complete[gb_pos_cash_complete['LONG_TERM'] == 0]\n",
    "\n",
    "    gb_pos_cash_complete_long_term_by_curr = gb_pos_cash_complete_long_term.groupby('SK_ID_CURR').agg({\n",
    "        'CNT_INSTALMENT': 'mean',\n",
    "        'RATE_COMPLETED': 'mean',\n",
    "        'SK_ID_PREV': 'count',\n",
    "        'NUM_INSTALMENT': 'sum',\n",
    "        'LAST_12_MONTHS': 'sum',\n",
    "        'LAST_36_MONTHS': 'sum',\n",
    "        # 'SK_DPD':'sum',\n",
    "        # 'SK_DPD_DEF':'sum',\n",
    "    }).reset_index()\n",
    "\n",
    "    gb_pos_cash_complete_long_term_by_curr.rename(columns={col: 'LONG_TERM_' + col for col in gb_pos_cash_complete_long_term_by_curr.columns if col != 'SK_ID_CURR'}, inplace=True)\n",
    "\n",
    "    gb_pos_cash_complete_short_term_by_curr = gb_pos_cash_complete_short_term.groupby('SK_ID_CURR').agg({\n",
    "        'CNT_INSTALMENT': 'mean',\n",
    "        'RATE_COMPLETED': 'mean',\n",
    "        'SK_ID_PREV': 'count',\n",
    "        'NUM_INSTALMENT': 'sum',\n",
    "        'LAST_12_MONTHS': 'sum',\n",
    "        'LAST_36_MONTHS': 'sum',\n",
    "        'SK_DPD':'sum',\n",
    "        'SK_DPD_DEF':'sum',\n",
    "    }).reset_index()\n",
    "\n",
    "    gb_pos_cash_complete_short_term_by_curr.rename(columns={col: 'SHORT_TERM_' + col for col in gb_pos_cash_complete_short_term_by_curr.columns if col != 'SK_ID_CURR'}, inplace=True)\n",
    "\n",
    "    gb_pos_cash_not_complete['SHORT_CNT_INSTALMENT'] = gb_pos_cash_complete_short_term['CNT_INSTALMENT'] * gb_pos_cash_complete_short_term['SHORT_TERM']\n",
    "    gb_pos_cash_not_complete['LONG_CNT_INSTALMENT'] = gb_pos_cash_complete_long_term['CNT_INSTALMENT'] * gb_pos_cash_complete_long_term['LONG_TERM']\n",
    "\n",
    "    gb_pos_cash_not_complete_by_curr = gb_pos_cash_not_complete.groupby('SK_ID_CURR').agg({\n",
    "        # 'SHORT_CNT_INSTALMENT': 'sum',\n",
    "        # 'LONG_CNT_INSTALMENT' : 'sum',\n",
    "        'LAST_12_MONTHS': 'sum',\n",
    "        'LAST_36_MONTHS': 'sum',\n",
    "        'CNT_INSTALMENT_FUTURE': 'sum',\n",
    "        'SK_DPD':'sum',\n",
    "        'SK_DPD_DEF':'sum',\n",
    "    }).reset_index()\n",
    "\n",
    "    gb_pos_cash_not_complete_by_curr.rename(columns={col: 'NOT_COMPLETED_' + col for col in gb_pos_cash_not_complete_by_curr.columns if col != 'SK_ID_CURR'}, inplace=True)\n",
    "    gb_pos_cash_by_curr = gb_pos_cash_by_curr.merge(gb_pos_cash_complete_long_term_by_curr, on='SK_ID_CURR', how='left')\n",
    "    gb_pos_cash_by_curr = gb_pos_cash_by_curr.merge(gb_pos_cash_complete_short_term_by_curr, on='SK_ID_CURR', how='left')\n",
    "    gb_pos_cash_by_curr = gb_pos_cash_by_curr.merge(gb_pos_cash_not_complete_by_curr, on='SK_ID_CURR', how='left')\n",
    "\n",
    "    return gb_pos_cash_by_curr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installment Payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:00:26.596446Z",
     "iopub.status.busy": "2024-12-08T11:00:26.595879Z",
     "iopub.status.idle": "2024-12-08T11:00:26.631774Z",
     "shell.execute_reply": "2024-12-08T11:00:26.630232Z",
     "shell.execute_reply.started": "2024-12-08T11:00:26.596394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_installment_payment():\n",
    "    installment = pd.read_csv(os.path.join(ROOT, \"dseb63_installments_payments.csv\"))\n",
    "    installment['INSTALLMENT_PAYMENT_DIFF'] = installment['AMT_INSTALMENT'] - installment['AMT_PAYMENT']\n",
    "    installment['DIFF'] = installment['DAYS_INSTALMENT'] - installment['DAYS_ENTRY_PAYMENT']\n",
    "    # installment['DIFF'].fillna(0, inplace=True)\n",
    "    installment['LATE'] = installment['DIFF'] > 0\n",
    "    installment['EARLY'] = installment['DIFF'] <= 0\n",
    "\n",
    "    installment['LATE'] *= installment['DIFF']\n",
    "    installment['EARLY'] *= -installment['DIFF']\n",
    "\n",
    "    installment[\"LAST_30_DAYS\"] = installment[\"DAYS_ENTRY_PAYMENT\"] >= -30\n",
    "    installment[\"LAST_60_DAYS\"] = installment[\"DAYS_ENTRY_PAYMENT\"] >= -60\n",
    "    installment[\"LAST_90_DAYS\"] = installment[\"DAYS_ENTRY_PAYMENT\"] >= -90\n",
    "    installment[\"LAST_180_DAYS\"] = installment[\"DAYS_ENTRY_PAYMENT\"] >= -180\n",
    "    installment[\"LAST_365_DAYS\"] = installment[\"DAYS_ENTRY_PAYMENT\"] >= -365\n",
    "    installment[\"LAST_730_DAYS\"] = installment[\"DAYS_ENTRY_PAYMENT\"] >= -365*3 # 3 ye\n",
    "\n",
    "    installment[\"PAYMENT_LAST_30_DAYS\"] = installment[\"LAST_30_DAYS\"] * installment[\"AMT_PAYMENT\"]\n",
    "    installment[\"PAYMENT_LAST_60_DAYS\"] = installment[\"LAST_60_DAYS\"] * installment[\"AMT_PAYMENT\"]\n",
    "    installment[\"PAYMENT_LAST_90_DAYS\"] = installment[\"LAST_90_DAYS\"] * installment[\"AMT_PAYMENT\"]\n",
    "    installment[\"PAYMENT_LAST_180_DAYS\"] = installment[\"LAST_180_DAYS\"] * installment[\"AMT_PAYMENT\"]\n",
    "    installment[\"PAYMENT_LAST_365_DAYS\"] = installment[\"LAST_365_DAYS\"] * installment[\"AMT_PAYMENT\"]\n",
    "    installment[\"PAYMENT_LAST_730_DAYS\"] = installment[\"LAST_730_DAYS\"] * installment[\"AMT_PAYMENT\"]\n",
    "\n",
    "    installment[\"LATENESS_LAST_90_DAYS\"] = installment[\"LAST_90_DAYS\"] * installment[\"LATE\"]\n",
    "    installment[\"LATENESS_LAST_180_DAYS\"] = installment[\"LAST_180_DAYS\"] * installment[\"LATE\"]\n",
    "    installment[\"LATENESS_LAST_365_DAYS\"] = installment[\"LAST_365_DAYS\"] * installment[\"LATE\"]\n",
    "    installment[\"LATENESS_LAST_730_DAYS\"] = installment[\"LAST_730_DAYS\"] * installment[\"LATE\"]\n",
    "\n",
    "    installment[\"EARLYNESS_LAST_90_DAYS\"] = installment[\"LAST_90_DAYS\"] * installment[\"EARLY\"]\n",
    "    installment[\"EARLYNESS_LAST_180_DAYS\"] = installment[\"LAST_180_DAYS\"] * installment[\"EARLY\"]\n",
    "    installment[\"EARLYNESS_LAST_365_DAYS\"] = installment[\"LAST_365_DAYS\"] * installment[\"EARLY\"]\n",
    "    installment[\"EARLYNESS_LAST_730_DAYS\"] = installment[\"LAST_730_DAYS\"] * installment[\"EARLY\"]\n",
    "\n",
    "    installment[\"PAYMENT_LATENESS_LAST_180_DAYS\"] = installment[\"LAST_180_DAYS\"] * installment[\"LATENESS_LAST_180_DAYS\"]\n",
    "    installment[\"PAYMENT_LATENESS_LAST_365_DAYS\"] = installment[\"LAST_365_DAYS\"] * installment[\"LATENESS_LAST_365_DAYS\"]\n",
    "    installment[\"PAYMENT_LATENESS_LAST_730_DAYS\"] = installment[\"LAST_730_DAYS\"] * installment[\"LATENESS_LAST_730_DAYS\"]\n",
    "\n",
    "    installment[\"PAYMENT_EARLYNESS_LAST_180_DAYS\"] = installment[\"LAST_180_DAYS\"] * installment[\"EARLYNESS_LAST_180_DAYS\"]\n",
    "    installment[\"PAYMENT_EARLYNESS_LAST_365_DAYS\"] = installment[\"LAST_365_DAYS\"] * installment[\"EARLYNESS_LAST_365_DAYS\"]\n",
    "    installment[\"PAYMENT_EARLYNESS_LAST_730_DAYS\"] = installment[\"LAST_730_DAYS\"] * installment[\"EARLYNESS_LAST_730_DAYS\"]\n",
    "\n",
    "    installment['INSTALLMENT_PAYMENT_DIFF_LAST_180_DAYS'] = installment['INSTALLMENT_PAYMENT_DIFF'] * installment['LAST_180_DAYS']\n",
    "    installment['INSTALLMENT_PAYMENT_DIFF_LAST_365_DAYS'] = installment['INSTALLMENT_PAYMENT_DIFF'] * installment['LAST_365_DAYS']\n",
    "    installment['INSTALLMENT_PAYMENT_DIFF_LAST_730_DAYS'] = installment['INSTALLMENT_PAYMENT_DIFF'] * installment['LAST_730_DAYS']\n",
    "\n",
    "    installment['COUNT'] = 1\n",
    "\n",
    "    gb_installment = installment.groupby('SK_ID_PREV').agg({'SK_ID_CURR':'first', \n",
    "                                                            'NUM_INSTALMENT_NUMBER':'max', \n",
    "                                                            'COUNT':'sum', \n",
    "                                                            'DIFF':['sum', 'mean', 'std'],\n",
    "                                                            'LATE': ['sum', 'mean', 'std'], \n",
    "                                                            'EARLY': ['sum', 'mean', 'std'], \n",
    "                                                            'DAYS_ENTRY_PAYMENT':'max', \n",
    "                                                            'INSTALLMENT_PAYMENT_DIFF' : ['sum', 'mean', 'std'],\n",
    "                                                            'AMT_PAYMENT':'sum',\n",
    "                                                            \n",
    "                                                            'LAST_30_DAYS':'sum', \n",
    "                                                            'LAST_60_DAYS':'sum', \n",
    "                                                            'LAST_90_DAYS':'sum', \n",
    "                                                            'LAST_180_DAYS':'sum', \n",
    "                                                            'LAST_365_DAYS':'sum', \n",
    "                                                            'LAST_730_DAYS':'sum', \n",
    "                                                            \n",
    "                                                            'PAYMENT_LAST_30_DAYS':['sum', 'mean', 'std'],  # 'max',\n",
    "                                                            'PAYMENT_LAST_60_DAYS':['sum', 'mean', 'std'], \n",
    "                                                            'PAYMENT_LAST_90_DAYS':['sum', 'mean', 'std', 'max','min'], \n",
    "                                                            'PAYMENT_LAST_180_DAYS':['sum', 'mean', 'std'], \n",
    "                                                            'PAYMENT_LAST_365_DAYS':['sum', 'mean', 'std', 'max','min'], \n",
    "                                                            'PAYMENT_LAST_730_DAYS':['sum', 'mean', 'std'],\n",
    "                                                            \n",
    "                                                            'LATENESS_LAST_90_DAYS':['sum', 'mean'],\n",
    "                                                            'LATENESS_LAST_180_DAYS':['sum', 'mean', 'std'],\n",
    "                                                            'LATENESS_LAST_365_DAYS':['sum', 'mean'],\n",
    "                                                            'LATENESS_LAST_730_DAYS':['sum', 'mean', 'std'],\n",
    "                                                            \n",
    "                                                            'EARLYNESS_LAST_90_DAYS':['sum', 'mean'],\n",
    "                                                            'EARLYNESS_LAST_180_DAYS':['sum', 'mean', 'std'],\n",
    "                                                            'EARLYNESS_LAST_365_DAYS':['sum', 'mean'],\n",
    "                                                            'EARLYNESS_LAST_730_DAYS':['sum', 'mean', 'std'],\n",
    "                                                            \n",
    "                                                            'PAYMENT_LATENESS_LAST_180_DAYS':['sum', 'mean'],\n",
    "                                                            'PAYMENT_LATENESS_LAST_365_DAYS':['sum', 'mean', 'std', 'max'],\n",
    "                                                            'PAYMENT_LATENESS_LAST_730_DAYS':['sum', 'mean', 'std'],\n",
    "                                                            \n",
    "                                                            'PAYMENT_EARLYNESS_LAST_180_DAYS':['sum', 'mean'],\n",
    "                                                            'PAYMENT_EARLYNESS_LAST_365_DAYS':['sum', 'mean', 'std', 'max'],\n",
    "                                                            'PAYMENT_EARLYNESS_LAST_730_DAYS':['sum', 'mean', 'std'],\n",
    "                                                            \n",
    "                                                            'INSTALLMENT_PAYMENT_DIFF_LAST_180_DAYS':['sum', 'mean', 'std'],\n",
    "                                                            'INSTALLMENT_PAYMENT_DIFF_LAST_365_DAYS':['sum', 'mean', 'std', 'max'],\n",
    "                                                            'INSTALLMENT_PAYMENT_DIFF_LAST_730_DAYS':['sum', 'mean', 'std', 'max'],\n",
    "                                                            \n",
    "                                                            }).reset_index()\n",
    "\n",
    "    gb_installment.columns = ['_'.join(col).strip() for col in gb_installment.columns.values]\n",
    "    # gb_installment.rename(columns={'COUNT':'NUM_INSTALMENT', 'LATE':'LATE_PAYMENT', 'EARLY':'EARLY_PAYMENT', 'DAYS_ENTRY_PAYMENT':'LASTEST_PAYMENT_DATE', 'AMT_PAYMENT':'TOTAL_PAYMENT'}, inplace=True)\n",
    "    gb_installment['MEAN_INSTALLMENT'] = gb_installment['AMT_PAYMENT_sum'] / gb_installment['NUM_INSTALMENT_NUMBER_max']\n",
    "\n",
    "    gb_installment.rename({ 'SK_ID_PREV_': 'SK_ID_PREV', 'SK_ID_CURR_first': 'SK_ID_CURR'}, axis=1, inplace=True)\n",
    "    # gb_mean_installment = gb_installment.groupby('SK_ID_CURR').agg({'MEAN_INSTALLMENT':'mean'}).reset_index()\n",
    "    gb_installment_by_curr = installment.groupby('SK_ID_CURR').agg({\n",
    "                                                            'NUM_INSTALMENT_NUMBER':'max', \n",
    "                                                            'COUNT':'sum', \n",
    "                                                            'DIFF':['sum', 'mean', 'std'],\n",
    "                                                            'LATE': ['sum', 'mean', 'std'], \n",
    "                                                            'EARLY': ['sum', 'mean', 'std'], \n",
    "                                                            'DAYS_ENTRY_PAYMENT':'max', \n",
    "                                                            'INSTALLMENT_PAYMENT_DIFF' : ['sum', 'mean', 'std'],\n",
    "                                                            'AMT_PAYMENT':'sum',\n",
    "                                                            \n",
    "                                                            'LAST_60_DAYS':'sum', \n",
    "                                                            'LAST_90_DAYS':'sum', \n",
    "                                                            'LAST_180_DAYS':'sum', \n",
    "                                                            'LAST_365_DAYS':'sum', \n",
    "                                                            'LAST_730_DAYS':'sum', \n",
    "                                                            \n",
    "                                                            'PAYMENT_LAST_30_DAYS':['sum', 'mean', 'std'], \n",
    "                                                            'PAYMENT_LAST_60_DAYS':['sum', 'mean', 'std'], \n",
    "                                                            'PAYMENT_LAST_90_DAYS':['sum', 'mean', 'std', 'max'], \n",
    "                                                            'PAYMENT_LAST_180_DAYS':['sum', 'mean', 'std'], \n",
    "                                                            'PAYMENT_LAST_365_DAYS':['sum', 'mean', 'std', 'max','min'], # drop min ?\n",
    "                                                            'PAYMENT_LAST_730_DAYS':['sum', 'mean', 'std'],\n",
    "                                                            \n",
    "                                                            'LATENESS_LAST_90_DAYS':['sum', 'mean'],\n",
    "                                                            'LATENESS_LAST_180_DAYS':['sum', 'mean', 'std'],\n",
    "                                                            'LATENESS_LAST_365_DAYS':['sum', 'mean'],\n",
    "                                                            'LATENESS_LAST_730_DAYS':['sum', 'mean', 'std', 'max'],\n",
    "                                                            \n",
    "                                                            'EARLYNESS_LAST_90_DAYS':['sum', 'mean'],\n",
    "                                                            'EARLYNESS_LAST_180_DAYS':['sum', 'mean', 'std',],\n",
    "                                                            'EARLYNESS_LAST_365_DAYS':['sum', 'mean'],\n",
    "                                                            'EARLYNESS_LAST_730_DAYS':['sum', 'mean', 'std', 'max'],\n",
    "                                                            \n",
    "                                                            'PAYMENT_LATENESS_LAST_180_DAYS':['sum', 'mean'],\n",
    "                                                            'PAYMENT_LATENESS_LAST_365_DAYS':['sum', 'mean', 'std'],\n",
    "                                                            'PAYMENT_LATENESS_LAST_730_DAYS':['sum', 'mean', 'std', 'max'],\n",
    "                                                            \n",
    "                                                            'PAYMENT_EARLYNESS_LAST_180_DAYS':['sum', 'mean'],\n",
    "                                                            'PAYMENT_EARLYNESS_LAST_365_DAYS':['sum', 'mean', 'std'],\n",
    "                                                            'PAYMENT_EARLYNESS_LAST_730_DAYS':['sum', 'mean', 'std', 'max'],\n",
    "                                                            \n",
    "                                                            'INSTALLMENT_PAYMENT_DIFF_LAST_180_DAYS':['sum', 'mean', 'std'],\n",
    "                                                            'INSTALLMENT_PAYMENT_DIFF_LAST_365_DAYS':['sum', 'mean', 'std', 'max'],\n",
    "                                                            'INSTALLMENT_PAYMENT_DIFF_LAST_730_DAYS':['sum', 'mean', 'std','max'],\n",
    "                                                            \n",
    "                                                            }).reset_index()\n",
    "\n",
    "    gb_installment_by_curr.columns = ['_'.join(col).strip() for col in gb_installment_by_curr.columns.values]\n",
    "    gb_installment_by_curr.rename({ 'SK_ID_CURR_': 'SK_ID_CURR'}, axis=1, inplace=True)\n",
    "\n",
    "    gb_installment_short_term = gb_installment[gb_installment['NUM_INSTALMENT_NUMBER_max'] <= 12]\n",
    "    gb_installment_long_term = gb_installment[gb_installment['NUM_INSTALMENT_NUMBER_max'] > 12]\n",
    "\n",
    "    gb_installment_short_term_by_curr = gb_installment_short_term.groupby('SK_ID_CURR').agg({'COUNT_sum':'sum', \n",
    "                                                                                            'NUM_INSTALMENT_NUMBER_max':'mean', \n",
    "                                                                                            'MEAN_INSTALLMENT':'mean', \n",
    "                                                                                            'LATE_sum':'mean', \n",
    "                                                                                            'EARLY_sum':'mean', \n",
    "                                                                                            'DAYS_ENTRY_PAYMENT_max':'max', \n",
    "                                                                                            'AMT_PAYMENT_sum':'sum', \n",
    "                                                                                            \n",
    "                                                                                            'LAST_90_DAYS_sum':'sum', \n",
    "                                                                                            'LAST_180_DAYS_sum':'sum', \n",
    "                                                                                            'LAST_365_DAYS_sum':'sum', \n",
    "                                                                                            'LAST_730_DAYS_sum':'sum',  \n",
    "                                                                                            \n",
    "                                                                                            'PAYMENT_LAST_90_DAYS_sum':'sum', \n",
    "                                                                                            'PAYMENT_LAST_180_DAYS_sum':'sum', \n",
    "                                                                                            'PAYMENT_LAST_365_DAYS_sum':'sum', \n",
    "                                                                                            'PAYMENT_LAST_730_DAYS_sum':'sum', \n",
    "                                                                                            'PAYMENT_LAST_730_DAYS_sum':'sum', \n",
    "                                                                                            \n",
    "                                                                                            }).reset_index()\n",
    "\n",
    "    # gb_installment_short_term_by_curr.columns = ['_'.join(col).strip() for col in gb_installment_short_term_by_curr.columns.values]\n",
    "    # gb_installment_short_term_by_curr.rename(columns={'SK_ID_CURR_': 'SK_ID_CURR'}, inplace=True)\n",
    "\n",
    "    gb_installment_short_term_by_curr.rename({ col: col + '_SHORT_TERM' for col in gb_installment_short_term_by_curr.columns if col != 'SK_ID_CURR' }, axis=1, inplace=True)\n",
    "\n",
    "    gb_installment_long_term_by_curr = gb_installment_long_term.groupby('SK_ID_CURR').agg({'COUNT_sum':'sum', \n",
    "                                                                                            'NUM_INSTALMENT_NUMBER_max':'mean', \n",
    "                                                                                            'MEAN_INSTALLMENT':'mean', \n",
    "                                                                                            'LATE_sum':'mean', \n",
    "                                                                                            'EARLY_sum':'mean', \n",
    "                                                                                            'DAYS_ENTRY_PAYMENT_max':'max', \n",
    "                                                                                            'AMT_PAYMENT_sum':'sum', \n",
    "                                                                                            \n",
    "                                                                                            'LAST_90_DAYS_sum':'sum', \n",
    "                                                                                            'LAST_180_DAYS_sum':'sum', \n",
    "                                                                                            'LAST_365_DAYS_sum':'sum', \n",
    "                                                                                            'LAST_730_DAYS_sum':'sum',  \n",
    "                                                                                            \n",
    "                                                                                            'PAYMENT_LAST_90_DAYS_sum':'sum', \n",
    "                                                                                            'PAYMENT_LAST_180_DAYS_sum':'sum', \n",
    "                                                                                            'PAYMENT_LAST_365_DAYS_sum':'sum', \n",
    "                                                                                            'PAYMENT_LAST_730_DAYS_sum':'sum', \n",
    "                                                                                            'PAYMENT_LAST_730_DAYS_sum':'sum', \n",
    "                                                                                                                                                                                    \n",
    "                                                                                            }).reset_index()\n",
    "\n",
    "    # gb_installment_long_term_by_curr.columns = ['_'.join(col).strip() for col in gb_installment_long_term_by_curr.columns.values]\n",
    "    # gb_installment_long_term_by_curr.rename(columns={'SK_ID_CURR_': 'SK_ID_CURR'}, inplace=True)\n",
    "\n",
    "    gb_installment_long_term_by_curr.rename({ col: col + '_LONG_TERM' for col in gb_installment_long_term_by_curr.columns if col != 'SK_ID_CURR' }, axis=1, inplace=True)\n",
    "\n",
    "    gb_installment_by_curr = gb_installment_by_curr.merge(gb_installment_short_term_by_curr, on='SK_ID_CURR', how='left')\n",
    "    gb_installment_by_curr = gb_installment_by_curr.merge(gb_installment_long_term_by_curr, on='SK_ID_CURR', how='left')\n",
    "    return gb_installment_by_curr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:00:26.638330Z",
     "iopub.status.busy": "2024-12-08T11:00:26.637350Z",
     "iopub.status.idle": "2024-12-08T11:03:47.786384Z",
     "shell.execute_reply": "2024-12-08T11:03:47.784935Z",
     "shell.execute_reply.started": "2024-12-08T11:00:26.638238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "appl_train = pd.read_csv(os.path.join(ROOT,'dseb63_application_train.csv'), index_col=0)\n",
    "\n",
    "# ====== BUREAU ======\n",
    "\n",
    "bureau = process_bureau()\n",
    "# bureau = pd.read_parquet('../../data/dseb63_bureau_general_v3.parquet')\n",
    "bureau_columns = bureau.columns\n",
    "\n",
    "new_bureau_columns = {col: 'BUREAU_' + col for col in bureau_columns if col != 'SK_ID_CURR'} \n",
    "bureau.rename(columns=new_bureau_columns, inplace=True)\n",
    "\n",
    "# ====== PREVIOUS APPLICATION ======\n",
    "\n",
    "prev_app = process_app_prev()\n",
    "prev_app_columns = prev_app.columns\n",
    "\n",
    "new_prev_app_columns = {col: 'PREV_APP_' + col for col in prev_app_columns if col != 'SK_ID_CURR'}\n",
    "prev_app.rename(columns=new_prev_app_columns, inplace=True)\n",
    "\n",
    "# ====== INSTALLMENTS PAYMENTS ======\n",
    "\n",
    "installments = process_installment_payment()\n",
    "installments_columns = installments.columns\n",
    "\n",
    "installments.drop(columns= [col for col in installments_columns if 'TARGET' in col], inplace=True)\n",
    "\n",
    "new_installments_columns = {col: 'INSTALLMENTS_' + col for col in installments_columns if col != 'SK_ID_CURR'}\n",
    "installments.rename(columns=new_installments_columns, inplace=True)\n",
    "\n",
    "# ====== CREDIT CARD BALANCE ======\n",
    "\n",
    "credit_card = process_credit_card_balance()\n",
    "credit_card_columns = credit_card.columns\n",
    "\n",
    "new_credit_card_columns = {col: 'CREDIT_CARD_' + col for col in credit_card_columns if col != 'SK_ID_CURR'}\n",
    "credit_card.rename(columns=new_credit_card_columns, inplace=True)\n",
    "\n",
    "# ====== POS CASH BALANCE ======\n",
    "\n",
    "pos_cash = process_pos_cash_balance()\n",
    "pos_cash_columns = pos_cash.columns\n",
    "\n",
    "new_posh_cash_columns = {col: 'POS_CASH_' + col for col in pos_cash_columns if col != 'SK_ID_CURR'}\n",
    "pos_cash.rename(columns=new_posh_cash_columns, inplace=True)\n",
    "\n",
    "# ====== MERGE DATA ======\n",
    "\n",
    "X = appl_train.merge(bureau, on='SK_ID_CURR', how='left')\n",
    "X = X.merge(installments, on='SK_ID_CURR', how='left')\n",
    "X = X.merge(pos_cash, on='SK_ID_CURR', how='left')\n",
    "X = X.merge(credit_card, on='SK_ID_CURR', how='left')\n",
    "X = X.merge(prev_app, on='SK_ID_CURR', how='left')\n",
    "\n",
    "\n",
    "X_test_ = pd.read_csv(os.path.join(ROOT,'dseb63_application_test.csv'),  index_col=0)\n",
    "X_test_ = X_test_.merge(bureau, on='SK_ID_CURR', how='left')\n",
    "X_test_ = X_test_.merge(installments, on='SK_ID_CURR', how='left')\n",
    "X_test_ = X_test_.merge(pos_cash, on='SK_ID_CURR', how='left')\n",
    "X_test_ = X_test_.merge(credit_card, on='SK_ID_CURR', how='left')\n",
    "X_test_ = X_test_.merge(prev_app, on='SK_ID_CURR', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:03:47.788508Z",
     "iopub.status.busy": "2024-12-08T11:03:47.788109Z",
     "iopub.status.idle": "2024-12-08T11:03:47.794852Z",
     "shell.execute_reply": "2024-12-08T11:03:47.793503Z",
     "shell.execute_reply.started": "2024-12-08T11:03:47.788469Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def RELU(series):\n",
    "    return series.apply(lambda x: max(0, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:03:47.797457Z",
     "iopub.status.busy": "2024-12-08T11:03:47.796693Z",
     "iopub.status.idle": "2024-12-08T11:03:47.846003Z",
     "shell.execute_reply": "2024-12-08T11:03:47.844377Z",
     "shell.execute_reply.started": "2024-12-08T11:03:47.797407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_df(df):\n",
    "    # df = df.copy()\n",
    "    \n",
    "    df['EMERGENCYSTATE_MODE'].fillna('No', inplace=True)\n",
    "    # df['FONDKAPREMONT_MODE'].fillna('Unknown', inplace=True)\n",
    "    # df['WALLSMATERIAL_MODE'].fillna('Not Specified', inplace=True)\n",
    "    df['OCCUPATION_TYPE'].replace('IT staff', 'High skill tech staff', inplace=True)\n",
    "    df['OCCUPATION_TYPE'].replace('Realty agents', 'Sales staff', inplace=True)\n",
    "    # df['OCCUPATION_TYPE'].replace('HR staff', 'Laborers', inplace=True)\n",
    "    \n",
    "    # 'Managers',\n",
    "    df['OCCUPATION_TYPE'].replace(['High skill tech staff', 'HR staff', 'Secretaries'], np.nan, inplace=True)\n",
    "    df['OCCUPATION_TYPE'].replace(['Cleaning staff', 'Cooking staff', 'Waiters/barmen staff', 'Private service staff', 'Low-skill Laborers', 'Security staff'], np.nan, inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "    df.drop(columns=['HOUSETYPE_MODE'], inplace=True)\n",
    "\n",
    "    df['WALLSMATERIAL_MODE'].replace(['Block', 'Stone, brick'], 'Brick', inplace=True)\n",
    "    df['WALLSMATERIAL_MODE'].replace(['Others', 'Mixed', 'Monolithic', 'Not Specified', 'Wooden'], np.nan, inplace=True)\n",
    "    \n",
    "    \n",
    "    df['FONDKAPREMONT_MODE'].replace(['not specified', 'org spec account', 'reg oper account'], np.nan, inplace=True)\n",
    "\n",
    "\n",
    "    map_week_day = {\n",
    "    'MONDAY': 'week_day',\n",
    "    'TUESDAY': 'week_day',\n",
    "    'WEDNESDAY': 'week_day',\n",
    "    'THURSDAY': 'week_day',\n",
    "    'FRIDAY': 'week_day',\n",
    "    'SATURDAY': 'weekend',\n",
    "    'SUNDAY': 'weekend',\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    df['WEEKDAY_APPR_PROCESS_START'] = df['WEEKDAY_APPR_PROCESS_START'].map(map_week_day)\n",
    "\n",
    "    map_edu = {\n",
    "        'Lower secondary': 0,\n",
    "        'Secondary / secondary special': 1,\n",
    "        'Incomplete higher': 2,\n",
    "        'Higher education': 3,\n",
    "        'Academic degree': 5\n",
    "    }\n",
    "\n",
    "    df['NAME_EDUCATION_TYPE'] = df['NAME_EDUCATION_TYPE'].map(map_edu, na_action='ignore').astype(int).fillna(0)\n",
    "\n",
    "    df['NAME_FAMILY_STATUS'].replace('Unknown', 'Single / not married', inplace=True)\n",
    "    df['CODE_GENDER'].replace('XNA', 'F', inplace=True)\n",
    "    \n",
    "    df['DAYS_EMPLOYED'] = df['DAYS_EMPLOYED'].fillna(365243)\n",
    "    # df['DAYS_EMPLOYED'] = df['DAYS_EMPLOYED'].replace(0, 365243)\n",
    "\n",
    "    # others = df['NAME_INCOME_TYPE'].value_counts().index[4:]\n",
    "    df['NAME_INCOME_TYPE'].replace(['Pensioner', 'Unemployed', 'Student','Businessman','Maternity leave'], np.nan, inplace=True)\n",
    "\n",
    "    \n",
    "    # df['NAME_TYPE_SUITE'].fillna('Unaccompanied', inplace=True)\n",
    "    df['NAME_TYPE_SUITE'].replace(['Spouse, partner', 'Group of people', 'Other_A', 'Other_B'], np.nan, inplace=True)\n",
    "\n",
    "    df['NAME_HOUSING_TYPE'].replace(['With parents', 'Municipal apartment', 'Rented apartment', 'Co-op apartment'], np.nan, inplace=True)\n",
    "\n",
    "    df['OWN_CAR_AGE'].fillna(-100, inplace=True)\n",
    "    df['TOTALAREA_MODE'].fillna(0, inplace=True)\n",
    "    \n",
    "    df['AGE_INT'] = -df['DAYS_BIRTH'] // 365\n",
    "    # Steal code\n",
    "    df['DAYS_LAST_PHONE_CHANGE'].replace(0, np.nan, inplace=True)\n",
    "    \n",
    "    def group_organizations(org_type):\n",
    "        if not isinstance(org_type, str):\n",
    "            return org_type\n",
    "        if 'Trade' in org_type:\n",
    "            return np.nan\n",
    "        elif 'Industry' in org_type:\n",
    "            return 'Industry'\n",
    "        elif 'Business' in org_type:\n",
    "            return 'Business Entity'\n",
    "        elif 'Transport' in org_type:\n",
    "            return 'Transport'\n",
    "        elif 'University' in org_type:\n",
    "            return 'School'\n",
    "        elif org_type in  ['Unknown', 'Insurance','Services', 'Insurance', 'Restaurant', 'Housing', 'Hotel', 'Agriculture', 'Cleaning', 'Other', 'Advertising','Police', 'Electricity', 'Culture', 'Religion', 'Telecom', 'Emergency', 'Mobile', 'Postal', 'Legal Services', 'Security', 'Security Ministries', 'Government']:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return org_type\n",
    "    \n",
    "    df['ORGANIZATION_TYPE'].replace('XNA', 'Unknown', inplace=True)\n",
    "    df['ORGANIZATION_TYPE'] = df['ORGANIZATION_TYPE'].apply(group_organizations)\n",
    "    \n",
    "    med_income = df.groupby(['ORGANIZATION_TYPE', 'NAME_EDUCATION_TYPE'])['AMT_INCOME_TOTAL'].transform('median')\n",
    "    med_income2 = df.groupby('ORGANIZATION_TYPE')['AMT_INCOME_TOTAL'].transform('median')\n",
    "    df['income_ratio'] = df['AMT_INCOME_TOTAL'] / med_income\n",
    "    df['income_ratio2'] = df['AMT_INCOME_TOTAL'] / med_income2\n",
    "    df['true_annuity_div_income'] = df['AMT_ANNUITY'] / med_income\n",
    "    df['true_annuity_div_income2'] = df['AMT_ANNUITY'] / med_income2\n",
    "    df['true_income_div_totalarea'] = med_income / df['TOTALAREA_MODE'].clip(0.001,1)\n",
    "    df['true_income_div_totalarea2'] = med_income2 / df['TOTALAREA_MODE'].clip(0.001,1)\n",
    "    \n",
    "    df['annuity_income_percentage'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['car_to_birth_ratio'] = RELU(df['OWN_CAR_AGE'] / df['DAYS_BIRTH'])\n",
    "    df['car_to_employ_ratio'] = RELU(df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED'])\n",
    "    df['children_ratio'] = df['CNT_CHILDREN'] / df['CNT_FAM_MEMBERS']\n",
    "    df['credit_to_annuity_ratio'] = df['AMT_CREDIT'] / df['AMT_ANNUITY'] # check\n",
    "    df['credit_to_goods_ratio'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
    "    df['credit_to_income_ratio'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "    \n",
    "    \n",
    "    df['ext_sources_mean'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "    df['ext_sources_sum'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].sum(axis=1)\n",
    "    df['ext_sources_var'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].var(axis=1)\n",
    "    df['ext_sources_weighted'] = df.EXT_SOURCE_1 * 2 + df.EXT_SOURCE_2 * 3 + df.EXT_SOURCE_3 * 4\n",
    "    df['EXT_SOURCE_MISSING_VALUES'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].isna().sum(axis=1)\n",
    "    \n",
    "    df['income_credit_percentage'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['income_per_child'] = df['AMT_INCOME_TOTAL'] / (df['CNT_CHILDREN'] + 1e-5) * (df['CNT_CHILDREN'] > 0) \n",
    "    df['income_per_person'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    df['phone_to_birth_ratio'] = RELU(df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH'])\n",
    "    df['phone_to_employ_ratio'] = RELU(df['DAYS_LAST_PHONE_CHANGE'] / (df['DAYS_EMPLOYED'] + 1e-5)) * (df['DAYS_EMPLOYED'] != 0) \n",
    "    \n",
    "    df['cnt_non_child'] = df['CNT_FAM_MEMBERS'] - df['CNT_CHILDREN']\n",
    "    df['child_to_non_child_ratio'] = df['CNT_CHILDREN'] / df['cnt_non_child'] * (df['cnt_non_child'] > 0)\n",
    "    df['income_per_non_child'] = df['AMT_INCOME_TOTAL'] / df['cnt_non_child']* (df['cnt_non_child'] > 0)\n",
    "    df['credit_per_person'] = df['AMT_CREDIT'] / df['CNT_FAM_MEMBERS']* (df['cnt_non_child'] > 0)\n",
    "    df['credit_per_child'] = df['AMT_CREDIT'] / (1 + df['CNT_CHILDREN'])\n",
    "    df['credit_per_non_child'] = df['AMT_CREDIT'] / df['cnt_non_child']* (df['cnt_non_child'] > 0)\n",
    "\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['DEBT_BURDEN_PER_WORKING_DAY'] = df['PAYMENT_RATE'] / (df['DAYS_EMPLOYED'] + 1e-5) * (df['DAYS_EMPLOYED'] != 0) \n",
    "    df['DEBT_BURDEN_PER_LIFE_DAY'] = df['PAYMENT_RATE'] / df['DAYS_BIRTH']\n",
    "    df['CREDIT_GOODS_PRICE_RATIO1'] = (df['AMT_CREDIT'] - df['AMT_GOODS_PRICE']) /  df['AMT_GOODS_PRICE']\n",
    "    df['CREDIT_GOODS_PRICE_RATIO2'] = (df['AMT_CREDIT'] - df['AMT_GOODS_PRICE']) /  df['AMT_CREDIT']\n",
    "    df['CREDIT_DOWN_PAYMENT'] = df['AMT_GOODS_PRICE'] - df['AMT_CREDIT']\n",
    "\n",
    "    df['sin_HOUR_APPR_PROCESS_START'] = np.sin(2 * np.pi * df['HOUR_APPR_PROCESS_START'] / 24)\n",
    "    df['cos_HOUR_APPR_PROCESS_START'] = np.cos(2 * np.pi * df['HOUR_APPR_PROCESS_START'] / 24)\n",
    "    df.drop(columns=['HOUR_APPR_PROCESS_START'], inplace=True)\n",
    "\n",
    "    docs = [f for f in df.columns if 'FLAG_DOC' in f]\n",
    "    df['NEW_DOC_IND_AVG'] = df[docs].mean(axis=1)\n",
    "    df['NEW_DOC_IND_STD'] = df[docs].std(axis=1)\n",
    "    df['NEW_DOC_IND_KURT'] = df[docs].kurtosis(axis=1)\n",
    "    df['HAS_DOCUMENT'] = df[docs].max(axis=1)\n",
    "    df['DOCUMENT_COUNT'] = df[docs].sum(axis=1)\n",
    "\n",
    "    #Drop flag document  \n",
    "    flag_document = [f for f in df.columns if 'FLAG_DOCUMENT_' in f]\n",
    "    df.drop(columns=flag_document, inplace=True)\n",
    "    \n",
    "    df['LIVINGAREA_AVG'] = df['LIVINGAREA_AVG'].fillna(0)\n",
    "    df['LANDAREA_AVG'] = df['LANDAREA_AVG'].fillna(0)\n",
    "    df['FLOORSMAX_AVG'] = df['FLOORSMAX_AVG'].fillna(0)\n",
    "    df['LIVINGAPARTMENTS_AVG'] = df['LIVINGAPARTMENTS_AVG'].fillna(0)\n",
    "    df['YEARS_BUILD_AVG'] = df['YEARS_BUILD_AVG'].fillna(0)\n",
    "\n",
    "    df['RATIO_AMT_GOODS_PRICE_TO_LIVINGAREA_AVG'] = (df['AMT_GOODS_PRICE'] / df['LIVINGAREA_AVG'].clip(0.05,1) +1e-5) * (df['LIVINGAREA_AVG'] / df['LIVINGAREA_AVG']+1e-5)\n",
    "    df['RATIO_AMT_GOODS_PRICE_TO_LANDAREA_AVG'] = (df['AMT_GOODS_PRICE'] / df['LANDAREA_AVG'].clip(0.05,1) +1e-5) * (df['LANDAREA_AVG'] / df['LANDAREA_AVG']+1e-5)\n",
    "    df['RATIO_AMT_GOODS_PRICE_TO_FLOORSMAX_AVG_AVG'] = (df['AMT_GOODS_PRICE'] / df['FLOORSMAX_AVG'].clip(0.05,1) +1e-5) * (df['FLOORSMAX_AVG'] / df['FLOORSMAX_AVG']+1e-5)\n",
    "    df['RATIO_AMT_GOODS_PRICE_TO_LIVINGAPARTMENTS_AVG'] = (df['AMT_GOODS_PRICE'] / df['LIVINGAPARTMENTS_AVG'].clip(0.05,1) +1e-5) * (df['LIVINGAPARTMENTS_AVG'] / df['LIVINGAPARTMENTS_AVG']+1e-5)\n",
    "    df['RATIO_AMT_GOODS_PRICE_TO_YEARS_BUILD_AVG'] = (df['AMT_GOODS_PRICE'] / df['YEARS_BUILD_AVG'].clip(0.05,1) +1e-5) * (df['YEARS_BUILD_AVG'] / df['YEARS_BUILD_AVG']+1e-5)\n",
    "    \n",
    "    # df['RATIO_AMT_GOODS_PRICE_TO_LIVINGAREA_AVG'] = df['AMT_GOODS_PRICE'] / df['LIVINGAREA_AVG'].clip(0.001,1)\n",
    "    # df['RATIO_AMT_GOODS_PRICE_TO_LANDAREA_AVG'] = df['AMT_GOODS_PRICE'] / df['LANDAREA_AVG'].clip(0.001,1)\n",
    "    # df['RATIO_AMT_GOODS_PRICE_TO_FLOORSMAX_AVG_AVG'] = df['AMT_GOODS_PRICE'] / df['FLOORSMAX_AVG'].clip(0.001,1)\n",
    "    # df['RATIO_AMT_GOODS_PRICE_TO_LIVINGAPARTMENTS_AVG'] = df['AMT_GOODS_PRICE'] / df['LIVINGAPARTMENTS_AVG'].clip(0.001,1) \n",
    "    # df['RATIO_AMT_GOODS_PRICE_TO_YEARS_BUILD_AVG'] = df['AMT_GOODS_PRICE'] / df['YEARS_BUILD_AVG'].clip(0.001,1)\n",
    "    \n",
    "    df['RELIABILITY_IN_CUSTOMER_CITY'] = df['REG_CITY_NOT_LIVE_CITY'] + df['REG_CITY_NOT_WORK_CITY'] + df['REG_REGION_NOT_LIVE_REGION'] + df['REG_REGION_NOT_WORK_REGION'] + df['LIVE_CITY_NOT_WORK_CITY'] + df['LIVE_REGION_NOT_WORK_REGION']\n",
    "    df['SUM_CONTACTS'] = df['FLAG_MOBIL'] + df['FLAG_EMP_PHONE'] + df['FLAG_WORK_PHONE'] + df['FLAG_CONT_MOBILE'] + df['FLAG_PHONE'] + df['FLAG_EMAIL']\n",
    "\n",
    "    #Some features from bureau \n",
    "    df['TOTAL_ENQUIRIES_CREDIT_BUREAU'] = df[['AMT_REQ_CREDIT_BUREAU_DAY',\n",
    "                                            'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "                                            'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    "                                            'AMT_REQ_CREDIT_BUREAU_MON',\n",
    "                                            'AMT_REQ_CREDIT_BUREAU_QRT',\n",
    "                                            'AMT_REQ_CREDIT_BUREAU_YEAR']].sum(axis=1)\n",
    "    \n",
    "    \n",
    "        \n",
    "    # df['PCTG_ENQUIRIES_HOUR'] = df['AMT_REQ_CREDIT_BUREAU_HOUR'] / df['TOTAL_ENQUIRIES_CREDIT_BUREAU']\n",
    "    # df['PCTG_ENQUIRIES_DAY'] = df['AMT_REQ_CREDIT_BUREAU_DAY'] / df['TOTAL_ENQUIRIES_CREDIT_BUREAU']\n",
    "    df['PCTG_ENQUIRIES_WEEK'] = df['AMT_REQ_CREDIT_BUREAU_WEEK'] / df['TOTAL_ENQUIRIES_CREDIT_BUREAU']\n",
    "    df['PCTG_ENQUIRIES_MON'] = df['AMT_REQ_CREDIT_BUREAU_MON'] / df['TOTAL_ENQUIRIES_CREDIT_BUREAU']\n",
    "    df['PCTG_ENQUIRIES_QRT'] = df['AMT_REQ_CREDIT_BUREAU_QRT'] / df['TOTAL_ENQUIRIES_CREDIT_BUREAU']\n",
    "    df['PCTG_ENQUIRIES_YEAR'] = df['AMT_REQ_CREDIT_BUREAU_YEAR'] / df['TOTAL_ENQUIRIES_CREDIT_BUREAU']\n",
    "\n",
    "    df.drop(columns=['AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_WEEK'], inplace=True)\n",
    "\n",
    "    missing_columns = ['APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG',\n",
    "                   'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG',\n",
    "                   'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG',\n",
    "                   'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG']\n",
    "\n",
    "    df['MISSING_GRADINGS'] = df[missing_columns].isna().sum(axis=1)\n",
    "    # Reliability in customer city or region of residence\n",
    "    df['RELIABILITY_IN_CUSTOMER_CITY'] = df['REG_CITY_NOT_LIVE_CITY'] + df['REG_CITY_NOT_WORK_CITY'] + df['REG_REGION_NOT_LIVE_REGION'] + df['REG_REGION_NOT_WORK_REGION'] + df['LIVE_CITY_NOT_WORK_CITY'] + df['LIVE_REGION_NOT_WORK_REGION']\n",
    "    df['SUM_CONTACTS'] = df['FLAG_MOBIL'] + df['FLAG_EMP_PHONE'] + df['FLAG_WORK_PHONE'] + df['FLAG_CONT_MOBILE'] + df['FLAG_PHONE'] + df['FLAG_EMAIL']\n",
    "\n",
    "    # numerical transformation\n",
    "    df['DAYS_EMPLOYED'].replace(365243,0, inplace=True)\n",
    "    df['days_employed_percentage'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    \n",
    "    \n",
    "\n",
    "    # vuxminhan params\n",
    "    df['REGION_POPULATION_RELATIVE'] = np.sqrt(df['REGION_POPULATION_RELATIVE'])\n",
    "    df['APARTMENTS_AVG'] = np.log1p(50 * df['APARTMENTS_AVG'])\n",
    "    # df['YEARS_BEGINEXPLUATATION_AVG'] = df['YEARS_BEGINEXPLUATATION_AVG'] ** 30 # New\n",
    "    df['YEARS_BUILD_AVG'] = df['YEARS_BUILD_AVG'] ** 3\n",
    "    df['COMMONAREA_AVG'] = df['COMMONAREA_AVG'].clip(0.000001,1) ** (-1/200)\n",
    "    df['ELEVATORS_AVG'] = df['ELEVATORS_AVG'] ** (1/40)\n",
    "    df['ENTRANCES_AVG'] = df['ENTRANCES_AVG'] ** (1/3)\n",
    "    df['FLOORSMAX_AVG'] = df['FLOORSMAX_AVG'] ** (1/2.5)\n",
    "    df['FLOORSMIN_AVG'] = df['FLOORSMIN_AVG'] ** (1/2.2)\n",
    "    df['LANDAREA_AVG'] = df['LANDAREA_AVG'] ** (1/5)\n",
    "    df['LIVINGAPARTMENTS_AVG'] = df['LIVINGAPARTMENTS_AVG'] ** (1/3)\n",
    "    df['LIVINGAREA_AVG'] = df['LIVINGAREA_AVG'] ** (1/3)\n",
    "    df['NONLIVINGAPARTMENTS_AVG'] = df['NONLIVINGAPARTMENTS_AVG'] ** (1/7)\n",
    "    df['NONLIVINGAREA_AVG'] = df['NONLIVINGAREA_AVG'] ** (1/5)\n",
    "    df['OBS_30_CNT_SOCIAL_CIRCLE'] = df['OBS_30_CNT_SOCIAL_CIRCLE'] ** (1/7)\n",
    "    df['DEF_30_CNT_SOCIAL_CIRCLE'] = df['DEF_30_CNT_SOCIAL_CIRCLE'] ** (1/7)\n",
    "    df['OBS_60_CNT_SOCIAL_CIRCLE'] = df['OBS_60_CNT_SOCIAL_CIRCLE'] ** (1/7)\n",
    "    df['DEF_60_CNT_SOCIAL_CIRCLE'] = df['DEF_60_CNT_SOCIAL_CIRCLE'] ** (1/7)\n",
    "\n",
    "def process_external(df):\n",
    "    df['ext_sources_mean'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "    df['ext_sources_sum'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].sum(axis=1)\n",
    "    df['ext_sources_var'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].var(axis=1)\n",
    "    df['ext_sources_weighted'] = df.EXT_SOURCE_1 * 2 + df.EXT_SOURCE_2 * 3 + df.EXT_SOURCE_3 * 4\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:03:47.848359Z",
     "iopub.status.busy": "2024-12-08T11:03:47.847825Z",
     "iopub.status.idle": "2024-12-08T11:03:53.010063Z",
     "shell.execute_reply": "2024-12-08T11:03:53.008726Z",
     "shell.execute_reply.started": "2024-12-08T11:03:47.848303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "process_df(X)\n",
    "process_df(X_test_)\n",
    "    \n",
    "process_external(X)\n",
    "process_external(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:03:53.012047Z",
     "iopub.status.busy": "2024-12-08T11:03:53.011540Z",
     "iopub.status.idle": "2024-12-08T11:03:53.046126Z",
     "shell.execute_reply": "2024-12-08T11:03:53.044847Z",
     "shell.execute_reply.started": "2024-12-08T11:03:53.012005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>RATIO_AMT_GOODS_PRICE_TO_YEARS_BUILD_AVG</th>\n",
       "      <th>RELIABILITY_IN_CUSTOMER_CITY</th>\n",
       "      <th>SUM_CONTACTS</th>\n",
       "      <th>TOTAL_ENQUIRIES_CREDIT_BUREAU</th>\n",
       "      <th>PCTG_ENQUIRIES_WEEK</th>\n",
       "      <th>PCTG_ENQUIRIES_MON</th>\n",
       "      <th>PCTG_ENQUIRIES_QRT</th>\n",
       "      <th>PCTG_ENQUIRIES_YEAR</th>\n",
       "      <th>MISSING_GRADINGS</th>\n",
       "      <th>days_employed_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.418984e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.159905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.152418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>490495.5</td>\n",
       "      <td>27517.5</td>\n",
       "      <td>454500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.093737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>1530000.0</td>\n",
       "      <td>42075.0</td>\n",
       "      <td>1530000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.023820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 885 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
       "0       0         Cash loans           F            N               N   \n",
       "1       0         Cash loans           F            N               Y   \n",
       "2       0         Cash loans           M            N               Y   \n",
       "3       0         Cash loans           M            N               Y   \n",
       "4       0         Cash loans           M            Y               Y   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          270000.0   1293502.5      35698.5        1129500.0   \n",
       "1             0          135000.0    312682.5      29686.5         297000.0   \n",
       "2             0          121500.0    513000.0      21865.5         513000.0   \n",
       "3             0           99000.0    490495.5      27517.5         454500.0   \n",
       "4             0          360000.0   1530000.0      42075.0        1530000.0   \n",
       "\n",
       "   ... RATIO_AMT_GOODS_PRICE_TO_YEARS_BUILD_AVG RELIABILITY_IN_CUSTOMER_CITY  \\\n",
       "0  ...                             1.418984e+06                            0   \n",
       "1  ...                                      NaN                            0   \n",
       "2  ...                                      NaN                            2   \n",
       "3  ...                                      NaN                            0   \n",
       "4  ...                                      NaN                            2   \n",
       "\n",
       "   SUM_CONTACTS TOTAL_ENQUIRIES_CREDIT_BUREAU PCTG_ENQUIRIES_WEEK  \\\n",
       "0             4                           0.0                 NaN   \n",
       "1             3                           0.0                 NaN   \n",
       "2             3                           0.0                 NaN   \n",
       "3             5                           2.0                 0.0   \n",
       "4             4                           0.0                 NaN   \n",
       "\n",
       "   PCTG_ENQUIRIES_MON  PCTG_ENQUIRIES_QRT  PCTG_ENQUIRIES_YEAR  \\\n",
       "0                 NaN                 NaN                  NaN   \n",
       "1                 NaN                 NaN                  NaN   \n",
       "2                 NaN                 NaN                  NaN   \n",
       "3                 0.0                 0.5                  0.5   \n",
       "4                 NaN                 NaN                  NaN   \n",
       "\n",
       "   MISSING_GRADINGS  days_employed_percentage  \n",
       "0                 0                  0.070862  \n",
       "1                 9                  0.159905  \n",
       "2                 9                  0.152418  \n",
       "3                 9                  0.093737  \n",
       "4                 9                  0.023820  \n",
       "\n",
       "[5 rows x 885 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:03:53.048156Z",
     "iopub.status.busy": "2024-12-08T11:03:53.047746Z",
     "iopub.status.idle": "2024-12-08T11:03:53.153839Z",
     "shell.execute_reply": "2024-12-08T11:03:53.152375Z",
     "shell.execute_reply.started": "2024-12-08T11:03:53.048118Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to free memory\n",
    "del bureau, installments, pos_cash, credit_card, prev_app\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:03:53.156043Z",
     "iopub.status.busy": "2024-12-08T11:03:53.155572Z",
     "iopub.status.idle": "2024-12-08T11:03:53.824697Z",
     "shell.execute_reply": "2024-12-08T11:03:53.823421Z",
     "shell.execute_reply.started": "2024-12-08T11:03:53.156005Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y = X['TARGET']\n",
    "X.drop(columns=['TARGET', 'SK_ID_CURR'], inplace=True)\n",
    "\n",
    "test_id = X_test_['SK_ID_CURR']\n",
    "X_test_.drop(columns=['SK_ID_CURR'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:03:53.827090Z",
     "iopub.status.busy": "2024-12-08T11:03:53.826597Z",
     "iopub.status.idle": "2024-12-08T11:03:53.839472Z",
     "shell.execute_reply": "2024-12-08T11:03:53.837965Z",
     "shell.execute_reply.started": "2024-12-08T11:03:53.827036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "high_null_cols = [\n",
    "    'BUREAU_SOLD_SUM_CREDIT',\n",
    "    'BUREAU_BAD_DEBT_LAST_5_YEAR',\n",
    "    'BUREAU_BAD_DEBT_FINISHED',\n",
    "    'BUREAU_BAD_DEBT_SUM_CREDIT',\n",
    "    'BUREAU_CLOSE_LATENCY_30_DAYS',\n",
    "    'BUREAU_SUM_OTHER',\n",
    "    'BUREAU_SUM_OVERDUE_MICROLOAN',\n",
    "    'BUREAU_SUM_DEBT_MICROLOAN',\n",
    "    'BUREAU_SUM_MICROLOAN',\n",
    "    'PREV_APP_APPROVED_RATE_INTEREST_PRIMARY_MIN',\n",
    "    'PREV_APP_APPROVED_RATE_INTEREST_PRIVILEGED_MAX',\n",
    "    'PREV_APP_APPROVED_RATE_INTEREST_PRIVILEGED_MEAN',\n",
    "    'PREV_APP_APPROVED_RATE_INTEREST_PRIMARY_MAX',\n",
    "    'PREV_APP_APPROVED_RATE_INTEREST_PRIVILEGED_MIN',\n",
    "    'PREV_APP_APPROVED_RATE_INTEREST_PRIMARY_MEAN',\n",
    "    'BUREAU_SOLD_DURATION',\n",
    "    'BUREAU_COUNT_SOLD',\n",
    "    'BUREAU_SOLD_LAST_1000_DAYS',\n",
    "    'BUREAU_SOLD_SUM_CREDIT', # 98.3\n",
    "\n",
    "    'BUREAU_ACTIVE_SUM_CREDIT_30_DAYS', # 97.16\n",
    "    'BUREAU_ACTIVE_SUM_DEBT_30_DAYS',\n",
    "    'BUREAU_ACTIVE_SUM_OVERDUE_30_DAYS',\n",
    "\n",
    "    'BUREAU_CLOSE_LATENCY_180_DAYS', # 96.6\n",
    "    'BUREAU_CLOSE_SUM_DEBT_180_DAYS', # 96.54\n",
    "    'BUREAU_CLOSE_SUM_OVERDUE_180_DAYS',\n",
    "    'BUREAU_CLOSE_SUM_CREDIT_180_DAYS',\n",
    "    # 'BUREAU_CLOSE_LATENCY_365_DAYS', #86\n",
    "\n",
    "    'BUREAU_SUM_MORTGAGE', # 95.35 -> 0.5644\n",
    "    'BUREAU_SUM_DEBT_MORTGAGE',\n",
    "    'BUREAU_SUM_OVERDUE_MORTGAGE',\n",
    "\n",
    "    'PREV_APP_REFUSED_AMT_DOWN_PAYMENT_STD', # 94.84\n",
    "\n",
    "    'BUREAU_SUM_CREDIT_CAR_LOAN', # 93.611\n",
    "    'BUREAU_SUM_OVERDUE_CAR_LOAN',\n",
    "    'BUREAU_SUM_DEBT_CAR_LOAN',\n",
    "\n",
    "    'BUREAU_CLOSE_SUM_CREDIT_LIFE_TIME', # 91.91\n",
    "\n",
    "    'PREV_APP_REFUSED_AMT_ANNUITY_SKEW', # 91.5\n",
    "    'PREV_APP_REFUSED_AMT_GOODS_PRICE_SKEW',\n",
    "    'PREV_APP_REFUSED_AMT_CREDIT_SKEW', # 89.9\n",
    "    'PREV_APP_REFUSED_AMT_APPLICATION_SKEW',\n",
    "\n",
    "    'POS_CASH_LONG_TERM_LAST_36_MONTHS', # 88.5\n",
    "    'POS_CASH_LONG_TERM_CNT_INSTALMENT',\n",
    "    'POS_CASH_LONG_TERM_LONG_TERM',\n",
    "    'POS_CASH_LONG_TERM_SK_DPD',\n",
    "    'POS_CASH_LONG_TERM_SK_DPD_DEF',\n",
    "    'POS_CASH_LONG_TERM_RATE_COMPLETED',\n",
    "    'POS_CASH_LONG_TERM_SK_ID_PREV',\n",
    "    'POS_CASH_LONG_TERM_NUM_INSTALMENT',\n",
    "    'POS_CASH_LONG_TERM_LAST_12_MONTHS', # 0.56612\n",
    "\n",
    "    'PREV_APP_REFUSED_RATE_DOWN_PAYMENT_MAX', # 85.3\n",
    "    'PREV_APP_REFUSED_AMT_DOWN_PAYMENT_MAX',\n",
    "    'PREV_APP_REFUSED_RATE_DOWN_PAYMENT_MEAN',\n",
    "    'PREV_APP_REFUSED_RATE_DOWN_PAYMENT_MIN',\n",
    "    'PREV_APP_REFUSED_AMT_DOWN_PAYMENT_MEAN',\n",
    "    'PREV_APP_REFUSED_AMT_DOWN_PAYMENT_MIN',\n",
    "\n",
    "    'PREV_APP_REFUSED_RATIO_GOODS_TO_ANNUITY_STD', # 84.7\n",
    "    'PREV_APP_REFUSED_RATIO_APPLICATION_TO_ANNUITY_STD',\n",
    "    'PREV_APP_REFUSED_CREDIT_ANNUITY_RATIO_STD',\n",
    "    'PREV_APP_REFUSED_ANNUITY_PAYMENT_PRODUCT_STD',\n",
    "    'PREV_APP_REFUSED_AMT_ANNUITY_STD',\n",
    "    'PREV_APP_REFUSED_AMT_GOODS_PRICE_STD', # 0.56626\n",
    "\n",
    "    'PREV_APP_REFUSED_APP_CREDIT_PERC_VAR', # 83.96\n",
    "    'PREV_APP_REFUSED_AMT_CREDIT_STD',\n",
    "    'PREV_APP_REFUSED_AMT_APPLICATION_STD',\n",
    "    'CREDIT_CARD_PERCENTAGE_OF_MINIMUM_PAYMENTS_MISSED_sum', # 0.56654\n",
    "\n",
    "    # 80\n",
    "\n",
    "    # Add cc_balance_v2\n",
    "    'CREDIT_CARD_PERCENTAGE_OF_MINIMUM_PAYMENTS_MISSED_var',\n",
    "    'CREDIT_CARD_SUM_ALL_AMT_DRAWINGS_var',\n",
    "    'CREDIT_CARD_RATIO_ALL_AMT_DRAWINGS_TO_ALL_CNT_DRAWINGS_var',\n",
    "    'CREDIT_CARD_SUM_ALL_CNT_DRAWINGS_var',\n",
    "    'CREDIT_CARD_CNT_DRAWINGS_ATM_CURRENT_std',\n",
    "    'CREDIT_CARD_PERCENTAGE_OF_MINIMUM_PAYMENTS_MISSED_max',\n",
    "    'CREDIT_CARD_SUM_ALL_AMT_DRAWINGS_max',\n",
    "    'CREDIT_CARD_RATIO_ALL_AMT_DRAWINGS_TO_ALL_CNT_DRAWINGS_mean',\n",
    "    'CREDIT_CARD_RATIO_ALL_AMT_DRAWINGS_TO_ALL_CNT_DRAWINGS_max',\n",
    "    'CREDIT_CARD_RATIO_ALL_AMT_DRAWINGS_TO_ALL_CNT_DRAWINGS_min',\n",
    "\n",
    "\n",
    "\n",
    "    'CREDIT_CARD_RATIO_ALL_AMT_DRAWINGS_TO_ALL_CNT_DRAWINGS_std' \n",
    "    'CREDIT_CARD_AMT_DRAWINGS_ATM_CURRENT_std',\n",
    "    'CREDIT_CARD_AMT_DRAWINGS_POS_CURRENT_std',\n",
    "    'CREDIT_CARD_SUM_ALL_CNT_DRAWINGS_mean',\n",
    "    'CREDIT_CARD_AMT_DRAWINGS_ATM_CURRENT_mean',\n",
    "    'CREDIT_CARD_CNT_DRAWINGS_ATM_CURRENT_mean',\n",
    "    'CREDIT_CARD_AMT_DRAWINGS_ATM_CURRENT_max',\n",
    "    'CREDIT_CARD_AMT_DRAWINGS_ATM_CURRENT_min',\n",
    "    'CREDIT_CARD_SUM_ALL_AMT_DRAWINGS_mean',\n",
    "    'CREDIT_CARD_AMT_DRAWINGS_POS_CURRENT_min',\n",
    "    'CREDIT_CARD_AMT_DRAWINGS_POS_CURRENT_max',\n",
    "    'CREDIT_CARD_AMT_DRAWINGS_POS_CURRENT_mean',\n",
    "    'CREDIT_CARD_RATIO_ALL_AMT_DRAWINGS_TO_ALL_CNT_DRAWINGS_mean', # 0.56664\n",
    "\n",
    "    'BUREAU_GENERAL_AMT_ANNUITY_std',\n",
    "    'BUREAU_ACTIVE_SUM_OVERDUE_LIFE_TIME',\n",
    "    'BUREAU_ACTIVE_SUM_CREDIT_LIFE_TIME', # 0.56670\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:03:53.841515Z",
     "iopub.status.busy": "2024-12-08T11:03:53.841114Z",
     "iopub.status.idle": "2024-12-08T11:03:53.980703Z",
     "shell.execute_reply": "2024-12-08T11:03:53.979513Z",
     "shell.execute_reply.started": "2024-12-08T11:03:53.841466Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for col in high_null_cols:\n",
    "    if col in X_test_.columns:\n",
    "        X_test_[col].fillna(0, inplace=True)\n",
    "        X[col].fillna(0,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:03:53.982816Z",
     "iopub.status.busy": "2024-12-08T11:03:53.982317Z",
     "iopub.status.idle": "2024-12-08T11:03:54.551160Z",
     "shell.execute_reply": "2024-12-08T11:03:54.549921Z",
     "shell.execute_reply.started": "2024-12-08T11:03:53.982740Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PowerTransformer, OrdinalEncoder, LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:03:54.553386Z",
     "iopub.status.busy": "2024-12-08T11:03:54.552807Z",
     "iopub.status.idle": "2024-12-08T11:03:56.719217Z",
     "shell.execute_reply": "2024-12-08T11:03:56.717915Z",
     "shell.execute_reply.started": "2024-12-08T11:03:54.553346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ordinal_cols = ['FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'EMERGENCYSTATE_MODE', 'CODE_GENDER', 'NAME_CONTRACT_TYPE']\n",
    "float_cols = []\n",
    "int_cols = []\n",
    "cate_cols = []\n",
    "flag_cols = []\n",
    "for col in X.columns:\n",
    "    if col not in ordinal_cols:\n",
    "        if X[col].dtype == 'float64':\n",
    "            float_cols.append(col)\n",
    "            X[col] = X[col].astype('float64')\n",
    "        elif X[col].dtype == 'int64':\n",
    "\n",
    "            int_cols.append(col)\n",
    "            X[col] = X[col].astype('int64')\n",
    "        elif X[col].dtype == 'bool':\n",
    "            int_cols.append(col)\n",
    "            X[col] = X[col].astype('int64')\n",
    "\n",
    "        else:\n",
    "            cate_cols.append(col)\n",
    "            X[col] = X[col].astype('str')\n",
    "    else:\n",
    "        X[col] = X[col].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:03:56.721211Z",
     "iopub.status.busy": "2024-12-08T11:03:56.720733Z",
     "iopub.status.idle": "2024-12-08T11:03:56.937227Z",
     "shell.execute_reply": "2024-12-08T11:03:56.935869Z",
     "shell.execute_reply.started": "2024-12-08T11:03:56.721171Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUREAU_GENERAL_CREDIT_DURATION_std\n",
      "BUREAU_GENERAL_DEBT_PERCENTAGE_std\n",
      "BUREAU_GENERAL_UTILIZATION_RATIO_std\n",
      "INSTALLMENTS_DIFF_std\n",
      "INSTALLMENTS_LATE_std\n",
      "INSTALLMENTS_EARLY_std\n",
      "INSTALLMENTS_LATENESS_LAST_180_DAYS_std\n",
      "INSTALLMENTS_LATENESS_LAST_730_DAYS_std\n",
      "INSTALLMENTS_EARLYNESS_LAST_180_DAYS_std\n",
      "INSTALLMENTS_EARLYNESS_LAST_730_DAYS_std\n",
      "INSTALLMENTS_PAYMENT_LATENESS_LAST_365_DAYS_std\n",
      "INSTALLMENTS_PAYMENT_LATENESS_LAST_730_DAYS_std\n",
      "INSTALLMENTS_PAYMENT_EARLYNESS_LAST_365_DAYS_std\n",
      "INSTALLMENTS_PAYMENT_EARLYNESS_LAST_730_DAYS_std\n",
      "CREDIT_CARD_RATIO_ALL_AMT_DRAWINGS_TO_ALL_CNT_DRAWINGS_std\n",
      "CREDIT_CARD_6_MONTH_RATE_OF_PAYBACK_std\n",
      "CREDIT_CARD_6_MONTH_AMT_INST_MIN_REGULARITY_std\n",
      "CREDIT_CARD_6_MONTH_PRINCIPIAL_RATE_std\n",
      "CREDIT_CARD_12_MONTH_RATE_OF_PAYBACK_std\n",
      "CREDIT_CARD_12_MONTH_AMT_INST_MIN_REGULARITY_std\n",
      "CREDIT_CARD_12_MONTH_PRINCIPIAL_RATE_std\n",
      "CREDIT_CARD_36_MONTH_AMT_INST_MIN_REGULARITY_std\n",
      "PREV_APP_PREV_CREDIT_ANNUITY_RATIO_STD\n",
      "PREV_APP_PREV_DOWN_PAYMENT_RATIO_STD\n",
      "PREV_APP_PREV_GOODS_PRICE_RATIO_STD\n",
      "PREV_APP_PREV_RATIO_APPLICATION_TO_ANNUITY_STD\n",
      "PREV_APP_PREV_RATIO_GOODS_TO_ANNUITY_STD\n",
      "PREV_APP_APPROVED_DOWN_PAYMENT_RATIO_STD\n",
      "PREV_APP_APPROVED_GOODS_PRICE_RATIO_STD\n",
      "PREV_APP_APPROVED_FINISH_RATE_STD\n",
      "PREV_APP_APPROVED_RATIO_APPLICATION_TO_ANNUITY_STD\n",
      "PREV_APP_APPROVED_RATIO_GOODS_TO_ANNUITY_STD\n",
      "PREV_APP_REFUSED_CREDIT_ANNUITY_RATIO_STD\n",
      "PREV_APP_REFUSED_RATIO_APPLICATION_TO_ANNUITY_STD\n",
      "PREV_APP_REFUSED_RATIO_GOODS_TO_ANNUITY_STD\n",
      "NEW_DOC_IND_STD\n"
     ]
    }
   ],
   "source": [
    "# Test std to var on ratio\n",
    "for col in X.columns:\n",
    "    if '_std' in col.lower():\n",
    "        # if '_ratio' in col.lower():\n",
    "        if X[col].max() < 50_000: # Avoid large number\n",
    "            X[col] = X[col]**2\n",
    "            X_test_[col] = X_test_[col]**2\n",
    "            print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:03:56.939387Z",
     "iopub.status.busy": "2024-12-08T11:03:56.938863Z",
     "iopub.status.idle": "2024-12-08T11:04:01.052429Z",
     "shell.execute_reply": "2024-12-08T11:04:01.051063Z",
     "shell.execute_reply.started": "2024-12-08T11:03:56.939339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for col in float_cols:\n",
    "    X[col].fillna(X[col].mean(), inplace=True)\n",
    "    X_test_[col].fillna(X[col].mean(), inplace=True)\n",
    "    \n",
    "for col in int_cols:\n",
    "    X[col].fillna(X[col].mean(), inplace=True)\n",
    "    X_test_[col].fillna(X[col].mean(), inplace=True)\n",
    "    \n",
    "for col in cate_cols:\n",
    "    X[col].fillna(np.nan, inplace=True)\n",
    "    X_test_[col].fillna(np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:04:01.054695Z",
     "iopub.status.busy": "2024-12-08T11:04:01.054205Z",
     "iopub.status.idle": "2024-12-08T11:04:01.082083Z",
     "shell.execute_reply": "2024-12-08T11:04:01.080550Z",
     "shell.execute_reply.started": "2024-12-08T11:04:01.054642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def analyze_feat(series):\n",
    "    \n",
    "    # Check the type of the feature\n",
    "    type_ = series.dtype\n",
    "    if type_ != 'object':\n",
    "        \n",
    "    \n",
    "        # Check the skewness of the feature\n",
    "        skew = series.skew()\n",
    "        \n",
    "        # Check the kurtosis of the feature\n",
    "        kurt = series.kurt()\n",
    "        \n",
    "        # Check the missing values of the feature\n",
    "        missing = series.isnull().sum()\n",
    "        \n",
    "        # Can convert to interger?\n",
    "        is_interger = 0\n",
    "        \n",
    "        # Min, max, mean, median, std, unique values\n",
    "        min_ = series.min()\n",
    "        max_ = series.max()\n",
    "        mean_ = series.mean()\n",
    "        median_ = series.median()\n",
    "        std_ = series.std()\n",
    "    else:\n",
    "        skew = 0\n",
    "        kurt = 0\n",
    "        missing = 0\n",
    "        is_interger = False\n",
    "        min_ = 0\n",
    "        max_ = 0\n",
    "        mean_ = 0\n",
    "        median_ = 0\n",
    "        std_ = 0   \n",
    "        \n",
    "    unique_ = series.nunique()\n",
    "    \n",
    "    # Return the results as a row \n",
    "    return (type_, skew, kurt, missing, is_interger, min_, max_, mean_, median_, std_, unique_)\n",
    "\n",
    "def analyze_column(feature, df):\n",
    "    # Get the results for a specific feature\n",
    "    return [feature] + list(analyze_feat(df[feature]))\n",
    "   \n",
    "def analyze_df(df):\n",
    "    features = df.columns\n",
    "    if 'TARGET' in features:\n",
    "        df.drop(columns=['TARGET'], inplace=True)\n",
    "        features = df.columns\n",
    "    # Create a DataFrame to store the results\n",
    "    \n",
    "    results = []\n",
    "    # Loop through each feature\n",
    "    for feature in tqdm(features):\n",
    "        # Get the results\n",
    "        result = analyze_feat(df[feature])\n",
    "        \n",
    "        # Append the results as a new row\n",
    "        results.append([feature] + list(result))\n",
    "    \n",
    "    return pd.DataFrame(results, columns=['Feature', 'Type', 'Skewness', 'Kurtosis', 'Missing', 'Is Integer', 'Min', 'Max', 'Mean', 'Median', 'Std', 'Unique'])\n",
    "    \n",
    "    \n",
    "def power_scaler_col(df, skewness = 8, kurtosis = 50, use_cache = True):\n",
    "    # Return which columns for power transformation, which for standard scaler\n",
    "\n",
    "    df_num = df.select_dtypes(include=[np.number])\n",
    "    df_num.fillna(0, inplace=True)\n",
    "    df_result = analyze_df(df)\n",
    "\n",
    "    # Nunique < 100 -> Categorical feature -> Scale\n",
    "    df_result['Mask_nunique'] = df_result['Unique'] > 100\n",
    "    \n",
    "    # Skewness > 10 -> Power transformation\n",
    "    df_result['Mask_skew'] = df_result['Skewness'].abs() > skewness\n",
    "    \n",
    "    # Kurtosis > 15 -> Power transformation\n",
    "    df_result['Mask_kurt'] = (df_result['Kurtosis']-3).abs() > kurtosis\n",
    "    \n",
    "    # Missing > 9/10 dataset -> Scale\n",
    "    df_result['Mask_missing'] = df_result['Missing'] < 0.5 * df.shape[0]\n",
    "    \n",
    "    df_result['Mask'] = df_result['Mask_nunique'] & (df_result['Mask_skew'] | df_result['Mask_kurt']) & df_result['Mask_missing']\n",
    "    \n",
    "    df_result['Min_Max'] = ( df_result['Min'] == 0) & (df_result['Max'] < 20) & (df_result['Unique'] < 50) # 50/50\n",
    "\n",
    "    power_col = df_result[df_result['Mask'] == 1].Feature.tolist()\n",
    "    standard_col = df_result[(df_result['Mask'] == 0) & (df_result['Min_Max'] == 0)].Feature.tolist()\n",
    "    min_max_col = df_result[(df_result['Mask'] == 0) & (df_result['Min_Max'] == 1)].Feature.tolist()\n",
    "    \n",
    "    return power_col, standard_col, min_max_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:04:01.085009Z",
     "iopub.status.busy": "2024-12-08T11:04:01.084375Z",
     "iopub.status.idle": "2024-12-08T11:04:25.330961Z",
     "shell.execute_reply": "2024-12-08T11:04:25.329638Z",
     "shell.execute_reply.started": "2024-12-08T11:04:01.084950Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 869/869 [00:04<00:00, 184.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(468, 333, 68)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_col, standard_col, min_max_col = power_scaler_col(X[float_cols+int_cols], skewness= 3, kurtosis = 20, use_cache=False)\n",
    "len(power_col), len(standard_col), len(min_max_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:04:25.332574Z",
     "iopub.status.busy": "2024-12-08T11:04:25.332256Z",
     "iopub.status.idle": "2024-12-08T11:04:25.338168Z",
     "shell.execute_reply": "2024-12-08T11:04:25.336663Z",
     "shell.execute_reply.started": "2024-12-08T11:04:25.332544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_columns = X.columns\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNIMPUTE is too long. Use KNN instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:04:25.340279Z",
     "iopub.status.busy": "2024-12-08T11:04:25.339789Z",
     "iopub.status.idle": "2024-12-08T11:04:25.355950Z",
     "shell.execute_reply": "2024-12-08T11:04:25.354550Z",
     "shell.execute_reply.started": "2024-12-08T11:04:25.340228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "knn_imputer = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=500, n_jobs=-1))  \n",
    "])\n",
    "\n",
    "knn_imputer_2 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=500, n_jobs=-1))  \n",
    "])\n",
    "\n",
    "knn_imputer_3 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=500, n_jobs=-1))  \n",
    "])\n",
    "\n",
    "onehot_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "power_transformer = PowerTransformer()\n",
    "ordinal_transformer = OrdinalEncoder()\n",
    "scaler_transformer = StandardScaler()\n",
    "min_max_transformer = MinMaxScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', onehot_transformer, cate_cols),\n",
    "        ('power', power_transformer, power_col), # power_transformer\n",
    "        ('ordinal', ordinal_transformer, ordinal_cols),\n",
    "        ('scale', scaler_transformer, standard_col),\n",
    "        ('min_max', min_max_transformer, min_max_col)\n",
    "        \n",
    "    ],\n",
    "    n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:04:25.358176Z",
     "iopub.status.busy": "2024-12-08T11:04:25.357803Z",
     "iopub.status.idle": "2024-12-08T11:04:25.377101Z",
     "shell.execute_reply": "2024-12-08T11:04:25.375693Z",
     "shell.execute_reply.started": "2024-12-08T11:04:25.358134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "weak_df_col = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'credit_to_annuity_ratio', 'annuity_income_percentage']\n",
    "weak_df_col_2 = ['DAYS_ID_PUBLISH', 'DAYS_REGISTRATION', 'days_employed_percentage', 'car_to_birth_ratio', 'NAME_EDUCATION_TYPE', 'AGE_INT']\n",
    "weak_df_col_3 = ['PAYMENT_RATE',  'PREV_APP_APPROVED_CREDIT_DOWNPAYMENT_SUM', 'POS_CASH_GENERAL_CNT_INSTALMENT_mean', 'POS_CASH_GENERAL_CNT_INSTALMENT_FUTURE_sum', 'AMT_ANNUITY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:04:25.378941Z",
     "iopub.status.busy": "2024-12-08T11:04:25.378540Z",
     "iopub.status.idle": "2024-12-08T11:04:25.394395Z",
     "shell.execute_reply": "2024-12-08T11:04:25.392840Z",
     "shell.execute_reply.started": "2024-12-08T11:04:25.378898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def log_resample_data(X_train, y_train, rate = 0.2, decay = 0.7, return_idx = False, sampling_strategy = 0.1, modelling = False):\n",
    "    \n",
    "    posidx = (y_train == 1)\n",
    "    negidx = (y_train == 0)\n",
    "\n",
    "    # X_train = np.concatenate([X_train, y_train2], axis=1)\n",
    "    posidx = np.where(posidx)[0]\n",
    "    negidx = np.where(negidx)[0]\n",
    "\n",
    "    n_samples = int(len(negidx) * rate)\n",
    "\n",
    "    if posidx.sum() < n_samples: # Not enough positive samples\n",
    "        return X_train, y_train\n",
    "    \n",
    "    if modelling:\n",
    "        if sampling_strategy == 'auto':\n",
    "            sampling_strategy = 0.5 * (len(posidx) / len(negidx))\n",
    "\n",
    "        start = time.time()\n",
    "        lr = LogisticRegression(max_iter=5000, C=0.001, tol= 1e-5, random_state=42, class_weight='balanced') # Train a weak Log model\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_temp = lr.predict_proba(X_train[posidx, :])[:,1] # Get the probability of being positive\n",
    "        end = time.time()\n",
    "        print('Log fitted', end-start)\n",
    "\n",
    "\n",
    "        border_idx = np.where(y_temp < sampling_strategy)[0] # Find the border samples ()\n",
    "        mask = np.zeros(len(y_temp), dtype=bool) \n",
    "        mask[border_idx] = True\n",
    "\n",
    "        important_idx = posidx[mask]\n",
    "        not_important_idx = posidx[~mask]\n",
    "\n",
    "        len_import = len(important_idx)\n",
    "        len_not_import = len(not_important_idx)\n",
    "        len_data = len(posidx)\n",
    "\n",
    "        reverse_decay = (len_data - len_not_import * decay) / len_import\n",
    "\n",
    "        upscale_important = int(len_import/len_data * n_samples * reverse_decay)\n",
    "        upscale_not_important = int(len_not_import/len_data * n_samples * decay)\n",
    "\n",
    "        important_idx2 = resample(important_idx, n_samples=upscale_important, random_state=42)\n",
    "        not_important_idx2 = resample(not_important_idx, n_samples=upscale_not_important, random_state=42)\n",
    "\n",
    "        print('Near border sample:',len_import, 'Up to', upscale_important)\n",
    "        print('Far border sample:',len_not_import, 'Up to', upscale_not_important)\n",
    "\n",
    "        posidx2 = np.concatenate([important_idx2, not_important_idx2])\n",
    "        \n",
    "\n",
    "    else:\n",
    "        posidx2 = resample(posidx, n_samples=n_samples, random_state=42)\n",
    "\n",
    "    idx = np.concatenate([posidx2, negidx])\n",
    "    np.random.shuffle(idx)\n",
    "    \n",
    "    if return_idx:\n",
    "        return idx\n",
    "\n",
    "    if isinstance(X_train, pd.DataFrame):\n",
    "        return X_train.iloc[idx,:], y_train[idx]\n",
    "    else:\n",
    "        return X_train[idx,:], y_train[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:04:25.396582Z",
     "iopub.status.busy": "2024-12-08T11:04:25.396100Z",
     "iopub.status.idle": "2024-12-08T11:04:28.133419Z",
     "shell.execute_reply": "2024-12-08T11:04:28.132209Z",
     "shell.execute_reply.started": "2024-12-08T11:04:25.396528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:04:28.135223Z",
     "iopub.status.busy": "2024-12-08T11:04:28.134869Z",
     "iopub.status.idle": "2024-12-08T11:14:12.910707Z",
     "shell.execute_reply": "2024-12-08T11:14:12.909324Z",
     "shell.execute_reply.started": "2024-12-08T11:04:28.135192Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-ing\n",
      "1\n",
      "2\n",
      "3\n",
      "Weak features fitted 36.57365679740906\n",
      "Transforming data\n",
      "Data transformed 81.44982743263245\n"
     ]
    }
   ],
   "source": [
    "print('KNN-ing')\n",
    "start = time.time()\n",
    "knn_imputer.fit(X_train[weak_df_col], y) # fit on original data\n",
    "knn_imputer_2.fit(X_train[weak_df_col_2], y) # fit on original data\n",
    "knn_imputer_3.fit(X_train[weak_df_col_3], y)\n",
    "\n",
    "\n",
    "weak_feature_train = knn_imputer.predict_proba(X_train[weak_df_col])[:,1]\n",
    "weak_feature_val = knn_imputer.predict_proba(X_test_[weak_df_col])[:,1]\n",
    "print('1')\n",
    "\n",
    "weak_feature_train_2 = knn_imputer_2.predict_proba(X_train[weak_df_col_2])[:,1]\n",
    "weak_feature_val_2 = knn_imputer_2.predict_proba(X_test_[weak_df_col_2])[:,1]\n",
    "print('2')\n",
    "\n",
    "weak_feature_train_3 = knn_imputer_3.predict_proba(X_train[weak_df_col_3])[:,1]\n",
    "weak_feature_val_3 = knn_imputer_3.predict_proba(X_test_[weak_df_col_3])[:,1]\n",
    "print('3')\n",
    "\n",
    "end = time.time()\n",
    "print('Weak features fitted', end-start)\n",
    "\n",
    "print('Transforming data')\n",
    "start = time.time()\n",
    "\n",
    "preprocessor.fit(X) # fit on original data\n",
    "X_train = preprocessor.transform(X_train)\n",
    "X_test = preprocessor.transform(X_test_)\n",
    "end = time.time()\n",
    "print('Data transformed', end-start)\n",
    "\n",
    "\n",
    "X_train = np.concatenate([X_train, \n",
    "                            weak_feature_train.reshape(-1,1), \n",
    "                            weak_feature_train_2.reshape(-1,1),\n",
    "                            weak_feature_train_3.reshape(-1,1)\n",
    "                            ], axis=1)\n",
    "X_test = np.concatenate([X_test, \n",
    "                        weak_feature_val.reshape(-1,1), \n",
    "                        weak_feature_val_2.reshape(-1,1),\n",
    "                        weak_feature_val_3.reshape(-1,1)\n",
    "                        ], axis=1)\n",
    "\n",
    "cat_feature = preprocessor.named_transformers_['onehot'].get_feature_names_out(cate_cols)\n",
    "feature_names = np.concatenate([cat_feature, \n",
    "                                power_col, \n",
    "                                ordinal_cols, \n",
    "                                standard_col, \n",
    "                                min_max_col, \n",
    "                                ['a', 'b','c']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:14:12.913168Z",
     "iopub.status.busy": "2024-12-08T11:14:12.912705Z",
     "iopub.status.idle": "2024-12-08T11:14:14.460959Z",
     "shell.execute_reply": "2024-12-08T11:14:14.459330Z",
     "shell.execute_reply.started": "2024-12-08T11:14:12.913127Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idx = log_resample_data(X_train, y, rate = UPSAMPLE_RATIO, decay = 1.05, return_idx = True, sampling_strategy = 0.63)\n",
    "X_resampled = X_train[idx,:]\n",
    "y_resampled = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:14:14.462918Z",
     "iopub.status.busy": "2024-12-08T11:14:14.462500Z",
     "iopub.status.idle": "2024-12-08T11:14:26.093064Z",
     "shell.execute_reply": "2024-12-08T11:14:26.091628Z",
     "shell.execute_reply.started": "2024-12-08T11:14:14.462870Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME_TYPE_SUITE_nan\n",
      "NAME_INCOME_TYPE_nan\n",
      "NAME_HOUSING_TYPE_nan\n",
      "OCCUPATION_TYPE_nan\n",
      "ORGANIZATION_TYPE_nan\n",
      "FONDKAPREMONT_MODE_nan\n",
      "WALLSMATERIAL_MODE_nan\n"
     ]
    }
   ],
   "source": [
    "X_resampled = pd.DataFrame(X_resampled, columns=feature_names)\n",
    "X_test = pd.DataFrame(X_test, columns=feature_names)\n",
    "\n",
    "for col in feature_names:\n",
    "    if '_nan' in col:\n",
    "        print(col)\n",
    "        X_resampled.drop(columns=[col], inplace=True)\n",
    "        X_test.drop(columns=[col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:14:26.095269Z",
     "iopub.status.busy": "2024-12-08T11:14:26.094705Z",
     "iopub.status.idle": "2024-12-08T11:14:27.672270Z",
     "shell.execute_reply": "2024-12-08T11:14:27.670810Z",
     "shell.execute_reply.started": "2024-12-08T11:14:26.095213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bad_flag = ['FLAG_MOBIL',\n",
    " 'FLAG_EMP_PHONE' ,'FLAG_CONT_MOBILE', 'FLAG_EMAIL',\n",
    " 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n",
    " 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_WORK_CITY',\n",
    " 'LIVE_CITY_NOT_WORK_CITY', 'EMERGENCYSTATE_MODE']\n",
    "\n",
    "X_resampled.drop(columns=bad_flag, inplace=True)\n",
    "X_test.drop(columns=bad_flag, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:14:27.674380Z",
     "iopub.status.busy": "2024-12-08T11:14:27.673993Z",
     "iopub.status.idle": "2024-12-08T11:14:27.680060Z",
     "shell.execute_reply": "2024-12-08T11:14:27.678774Z",
     "shell.execute_reply.started": "2024-12-08T11:14:27.674343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "features = X_resampled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:14:27.681982Z",
     "iopub.status.busy": "2024-12-08T11:14:27.681541Z",
     "iopub.status.idle": "2024-12-08T11:14:27.868257Z",
     "shell.execute_reply": "2024-12-08T11:14:27.866932Z",
     "shell.execute_reply.started": "2024-12-08T11:14:27.681943Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X \n",
    "del X_train \n",
    "del X_test_\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:14:27.870194Z",
     "iopub.status.busy": "2024-12-08T11:14:27.869797Z",
     "iopub.status.idle": "2024-12-08T11:14:27.882024Z",
     "shell.execute_reply": "2024-12-08T11:14:27.880738Z",
     "shell.execute_reply.started": "2024-12-08T11:14:27.870158Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "def gini_coefficient(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Gini coefficient using predictions and true labels.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (array-like): True binary labels.\n",
    "    y_pred (array-like): Predicted probabilities.\n",
    "    \n",
    "    Returns:\n",
    "    float: Gini coefficient.\n",
    "    \"\"\"\n",
    "    auc = roc_auc_score(y_true, y_pred)  # AUC calculation\n",
    "    return 2 * auc - 1  # Gini coefficient\n",
    "gini_scorer = make_scorer(gini_coefficient, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:32:09.735676Z",
     "iopub.status.busy": "2024-12-08T11:32:09.734977Z",
     "iopub.status.idle": "2024-12-08T11:32:09.743164Z",
     "shell.execute_reply": "2024-12-08T11:32:09.741885Z",
     "shell.execute_reply.started": "2024-12-08T11:32:09.735616Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(random_state=42, max_iter=10000, class_weight='balanced', C = 0.01, tol = 1e-5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:32:17.476928Z",
     "iopub.status.busy": "2024-12-08T11:32:17.476441Z",
     "iopub.status.idle": "2024-12-08T11:46:59.471291Z",
     "shell.execute_reply": "2024-12-08T11:46:59.467812Z",
     "shell.execute_reply.started": "2024-12-08T11:32:17.476886Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time: 220.116149187088\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "logistic_model.fit(X_resampled[features], y_resampled)\n",
    "y_pred = logistic_model.predict_proba(X_test[features])\n",
    "end = time.time()\n",
    "print('Fitting time:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:46:59.479489Z",
     "iopub.status.busy": "2024-12-08T11:46:59.477117Z",
     "iopub.status.idle": "2024-12-08T11:46:59.497493Z",
     "shell.execute_reply": "2024-12-08T11:46:59.493741Z",
     "shell.execute_reply.started": "2024-12-08T11:46:59.479419Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': test_id,\n",
    "    'TARGET': y_pred[:, 1]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T11:46:59.502649Z",
     "iopub.status.busy": "2024-12-08T11:46:59.500700Z",
     "iopub.status.idle": "2024-12-08T11:46:59.712214Z",
     "shell.execute_reply": "2024-12-08T11:46:59.710540Z",
     "shell.execute_reply.started": "2024-12-08T11:46:59.502584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10139593,
     "sourceId": 88498,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
